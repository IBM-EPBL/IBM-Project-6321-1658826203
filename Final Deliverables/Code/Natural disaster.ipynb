{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pwd\n",
    "'/home/wsuser/work'\n",
    "import numpy as np\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Flatten, Conv2D, MaxPooling2D\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "import os, types\n",
    "import pandas as pd\n",
    "from botocore.client import Config\n",
    "import ibm_boto3\n",
    "\n",
    "def __iter__(self): return 0\n",
    "\n",
    "# @hidden_cell\n",
    "# The following code accesses a file in your IBM Cloud Object Storage. It includes your credentials.\n",
    "# You might want to remove those credentials before you share the notebook.\n",
    "cos_client = ibm_boto3.client(service_name='s3',\n",
    "    ibm_api_key_id='eqRr_BuHHp9Di6TVmW-MGXHyPXtsbYlsKBxJDrYcV7Yn',\n",
    "    ibm_auth_endpoint=\"https://iam.cloud.ibm.com/oidc/token\",\n",
    "    config=Config(signature_version='oauth'),\n",
    "    endpoint_url='https://s3.private.us.cloud-object-storage.appdomain.cloud')\n",
    "\n",
    "bucket = 'naturaldisastersintensityanalysis-donotdelete-pr-wij7ez8jjgzubp'\n",
    "object_key = 'dataset.zip'\n",
    "\n",
    "streaming_body_2 = cos_client.get_object(Bucket=bucket, Key=object_key)['Body']\n",
    "\n",
    "# Your data file was loaded into a botocore.response.StreamingBody object.\n",
    "# Please read the documentation of ibm_boto3 and pandas to learn more about the possibilities to load the data.\n",
    "# ibm_boto3 documentation: https://ibm.github.io/ibm-cos-sdk-python/\n",
    "# pandas documentation: http://pandas.pydata.org/\n",
    "from io import BytesIO\n",
    "import zipfile\n",
    "unzip = zipfile.ZipFile(BytesIO(streaming_body_2.read()),'r')\n",
    "file_paths = unzip.namelist()\n",
    "for path in file_paths:\n",
    "    unzip.extract(path)\n",
    "data_path = '/home/wsuser/work/Dataset/'\n",
    "batch_size = 32\n",
    "target_size = (64, 64)\n",
    "train_datagen = ImageDataGenerator(rescale=1./255,\n",
    "                                   shear_range=0.2,\n",
    "                                   zoom_range=0.2,\n",
    "                                   width_shift_range=0.1,\n",
    "                                   height_shift_range=0.1,\n",
    "                                   horizontal_flip=True,\n",
    "                                   validation_split=0.2)\n",
    "\n",
    "test_datagen = ImageDataGenerator(rescale=1. / 255, validation_split=0.2)\n",
    "X_train = train_datagen.flow_from_directory('/home/wsuser/work/dataset/train_set',\n",
    "                                            target_size=(64, 64),\n",
    "                                            batch_size=32,\n",
    "                                            color_mode=\"rgb\",\n",
    "                                            subset=\"training\",\n",
    "                                            class_mode='categorical')\n",
    "\n",
    "\n",
    "\n",
    "X_test = test_datagen.flow_from_directory('/home/wsuser/work/dataset/test_set',\n",
    "                                          target_size=(64, 64),\n",
    "                                          batch_size=32,\n",
    "                                          color_mode=\"rgb\",\n",
    "                                          subset=\"validation\",\n",
    "                                          class_mode='categorical')\n",
    "Found 595 images belonging to 4 classes.\n",
    "Found 37 images belonging to 4 classes.\n",
    "model = Sequential()\n",
    "model.add(Conv2D(32, (3, 3), input_shape=(64, 64, 3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Conv2D(32, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Flatten())\n",
    "\n",
    "model.add(Dense(units=128, activation='relu'))\n",
    "model.add(Dense(units=4, activation='softmax'))\n",
    "model.summary()\n",
    "Model: \"sequential\"\n",
    "_________________________________________________________________\n",
    " Layer (type)                Output Shape              Param #   \n",
    "=================================================================\n",
    " conv2d (Conv2D)             (None, 62, 62, 32)        896       \n",
    "                                                                 \n",
    " max_pooling2d (MaxPooling2D  (None, 31, 31, 32)       0         \n",
    " )                                                               \n",
    "                                                                 \n",
    " conv2d_1 (Conv2D)           (None, 29, 29, 32)        9248      \n",
    "                                                                 \n",
    " max_pooling2d_1 (MaxPooling  (None, 14, 14, 32)       0         \n",
    " 2D)                                                             \n",
    "                                                                 \n",
    " flatten (Flatten)           (None, 6272)              0         \n",
    "                                                                 \n",
    " dense (Dense)               (None, 128)               802944    \n",
    "                                                                 \n",
    " dense_1 (Dense)             (None, 4)                 516       \n",
    "                                                                 \n",
    "=================================================================\n",
    "Total params: 813,604\n",
    "Trainable params: 813,604\n",
    "Non-trainable params: 0\n",
    "_________________________________________________________________\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "model.fit(X_train, \n",
    "          steps_per_epoch=len(X_train), \n",
    "          epochs=20,\n",
    "          validation_data=X_test,\n",
    "          validation_steps=len(X_test))\n",
    "Epoch 1/20\n",
    "19/19 [==============================] - 28s 1s/step - loss: 1.2825 - accuracy: 0.4017 - val_loss: 1.1511 - val_accuracy: 0.5946\n",
    "Epoch 2/20\n",
    "19/19 [==============================] - 25s 1s/step - loss: 1.0187 - accuracy: 0.5933 - val_loss: 0.9829 - val_accuracy: 0.6757\n",
    "Epoch 3/20\n",
    "19/19 [==============================] - 25s 1s/step - loss: 0.8670 - accuracy: 0.6571 - val_loss: 1.2125 - val_accuracy: 0.4865\n",
    "Epoch 4/20\n",
    "19/19 [==============================] - 26s 1s/step - loss: 0.8239 - accuracy: 0.6723 - val_loss: 0.9556 - val_accuracy: 0.6757\n",
    "Epoch 5/20\n",
    "19/19 [==============================] - 25s 1s/step - loss: 0.7818 - accuracy: 0.6840 - val_loss: 1.0185 - val_accuracy: 0.6757\n",
    "Epoch 6/20\n",
    "19/19 [==============================] - 26s 1s/step - loss: 0.6352 - accuracy: 0.7714 - val_loss: 0.9754 - val_accuracy: 0.7568\n",
    "Epoch 7/20\n",
    "19/19 [==============================] - 26s 1s/step - loss: 0.5867 - accuracy: 0.7681 - val_loss: 0.8624 - val_accuracy: 0.7568\n",
    "Epoch 8/20\n",
    "19/19 [==============================] - 25s 1s/step - loss: 0.6245 - accuracy: 0.7681 - val_loss: 0.8863 - val_accuracy: 0.7027\n",
    "Epoch 9/20\n",
    "19/19 [==============================] - 25s 1s/step - loss: 0.6180 - accuracy: 0.7664 - val_loss: 1.5044 - val_accuracy: 0.6757\n",
    "Epoch 10/20\n",
    "19/19 [==============================] - 25s 1s/step - loss: 0.5976 - accuracy: 0.7765 - val_loss: 1.0201 - val_accuracy: 0.6757\n",
    "Epoch 11/20\n",
    "19/19 [==============================] - 25s 1s/step - loss: 0.5209 - accuracy: 0.8050 - val_loss: 0.8570 - val_accuracy: 0.7027\n",
    "Epoch 12/20\n",
    "19/19 [==============================] - 25s 1s/step - loss: 0.5374 - accuracy: 0.7899 - val_loss: 1.0046 - val_accuracy: 0.7297\n",
    "Epoch 13/20\n",
    "19/19 [==============================] - 25s 1s/step - loss: 0.5231 - accuracy: 0.7983 - val_loss: 0.8088 - val_accuracy: 0.7568\n",
    "Epoch 14/20\n",
    "19/19 [==============================] - 25s 1s/step - loss: 0.4615 - accuracy: 0.8303 - val_loss: 0.8695 - val_accuracy: 0.7568\n",
    "Epoch 15/20\n",
    "19/19 [==============================] - 26s 1s/step - loss: 0.4904 - accuracy: 0.8134 - val_loss: 1.0314 - val_accuracy: 0.7568\n",
    "Epoch 16/20\n",
    "19/19 [==============================] - 26s 1s/step - loss: 0.4355 - accuracy: 0.8286 - val_loss: 0.9395 - val_accuracy: 0.7568\n",
    "Epoch 17/20\n",
    "19/19 [==============================] - 25s 1s/step - loss: 0.4891 - accuracy: 0.8185 - val_loss: 0.9327 - val_accuracy: 0.7838\n",
    "Epoch 18/20\n",
    "19/19 [==============================] - 26s 1s/step - loss: 0.3950 - accuracy: 0.8487 - val_loss: 1.0022 - val_accuracy: 0.7568\n",
    "Epoch 19/20\n",
    "19/19 [==============================] - 25s 1s/step - loss: 0.4382 - accuracy: 0.8370 - val_loss: 0.9419 - val_accuracy: 0.8378\n",
    "Epoch 20/20\n",
    "19/19 [==============================] - 25s 1s/step - loss: 0.3950 - accuracy: 0.8387 - val_loss: 1.1659 - val_accuracy: 0.7297\n",
    "model.save(\"disaster.h5\")\n",
    "!tar -zcvf disaster.tgz disaster.h5\n",
    "disaster.h5\n",
    "ls\n",
    "dataset/  disaster.h5  disaster.tgz\n",
    "!pip install watson-machine-learning-client\n",
    "Collecting watson-machine-learning-client\n",
    "  Downloading watson_machine_learning_client-1.0.391-py3-none-any.whl (538 kB)\n",
    "     |████████████████████████████████| 538 kB 12.9 MB/s eta 0:00:01\n",
    "Requirement already satisfied: tqdm in /opt/conda/envs/Python-3.9/lib/python3.9/site-packages (from watson-machine-learning-client) (4.62.3)\n",
    "Requirement already satisfied: requests in /opt/conda/envs/Python-3.9/lib/python3.9/site-packages (from watson-machine-learning-client) (2.26.0)\n",
    "Requirement already satisfied: pandas in /opt/conda/envs/Python-3.9/lib/python3.9/site-packages (from watson-machine-learning-client) (1.3.4)\n",
    "Requirement already satisfied: urllib3 in /opt/conda/envs/Python-3.9/lib/python3.9/site-packages (from watson-machine-learning-client) (1.26.7)\n",
    "Requirement already satisfied: ibm-cos-sdk in /opt/conda/envs/Python-3.9/lib/python3.9/site-packages (from watson-machine-learning-client) (2.11.0)\n",
    "Requirement already satisfied: boto3 in /opt/conda/envs/Python-3.9/lib/python3.9/site-packages (from watson-machine-learning-client) (1.18.21)\n",
    "Requirement already satisfied: lomond in /opt/conda/envs/Python-3.9/lib/python3.9/site-packages (from watson-machine-learning-client) (0.3.3)\n",
    "Requirement already satisfied: tabulate in /opt/conda/envs/Python-3.9/lib/python3.9/site-packages (from watson-machine-learning-client) (0.8.9)\n",
    "Requirement already satisfied: certifi in /opt/conda/envs/Python-3.9/lib/python3.9/site-packages (from watson-machine-learning-client) (2022.9.24)\n",
    "Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in /opt/conda/envs/Python-3.9/lib/python3.9/site-packages (from boto3->watson-machine-learning-client) (0.10.0)\n",
    "Requirement already satisfied: botocore<1.22.0,>=1.21.21 in /opt/conda/envs/Python-3.9/lib/python3.9/site-packages (from boto3->watson-machine-learning-client) (1.21.41)\n",
    "Requirement already satisfied: s3transfer<0.6.0,>=0.5.0 in /opt/conda/envs/Python-3.9/lib/python3.9/site-packages (from boto3->watson-machine-learning-client) (0.5.0)\n",
    "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /opt/conda/envs/Python-3.9/lib/python3.9/site-packages (from botocore<1.22.0,>=1.21.21->boto3->watson-machine-learning-client) (2.8.2)\n",
    "Requirement already satisfied: six>=1.5 in /opt/conda/envs/Python-3.9/lib/python3.9/site-packages (from python-dateutil<3.0.0,>=2.1->botocore<1.22.0,>=1.21.21->boto3->watson-machine-learning-client) (1.15.0)\n",
    "Requirement already satisfied: ibm-cos-sdk-s3transfer==2.11.0 in /opt/conda/envs/Python-3.9/lib/python3.9/site-packages (from ibm-cos-sdk->watson-machine-learning-client) (2.11.0)\n",
    "Requirement already satisfied: ibm-cos-sdk-core==2.11.0 in /opt/conda/envs/Python-3.9/lib/python3.9/site-packages (from ibm-cos-sdk->watson-machine-learning-client) (2.11.0)\n",
    "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/envs/Python-3.9/lib/python3.9/site-packages (from requests->watson-machine-learning-client) (3.3)\n",
    "Requirement already satisfied: charset-normalizer~=2.0.0 in /opt/conda/envs/Python-3.9/lib/python3.9/site-packages (from requests->watson-machine-learning-client) (2.0.4)\n",
    "Requirement already satisfied: pytz>=2017.3 in /opt/conda/envs/Python-3.9/lib/python3.9/site-packages (from pandas->watson-machine-learning-client) (2021.3)\n",
    "Requirement already satisfied: numpy>=1.17.3 in /opt/conda/envs/Python-3.9/lib/python3.9/site-packages (from pandas->watson-machine-learning-client) (1.20.3)\n",
    "Installing collected packages: watson-machine-learning-client\n",
    "Successfully installed watson-machine-learning-client-1.0.391\n",
    "from ibm_watson_machine_learning import APIClient\n",
    "\n",
    "API_KEY = \"dI8836cei5gsTnRg5IXx2Jla_HxwNj1-FyYdDTq1oHkV\"\n",
    "\n",
    "wml_credentials = {\n",
    "    \"url\": \"https://us-south.ml.cloud.ibm.com\",\n",
    "    \"apikey\": API_KEY\n",
    "}\n",
    "\n",
    "client = APIClient(wml_credentials)\n",
    "client=APIClient(wml_credentials)\n",
    "def guid_from_space_name(client, space_name):\n",
    "    space = client.spaces.get_details()\n",
    "    return(next(item for item in space['resources'] if item['entity']['name'] == space_name)['metadata']['id'])\n",
    "space_uid = guid_from_space_name(client, 'Natural Disasters Intensity Analysis')\n",
    "print(\"Space UID: \", space_uid)\n",
    "Space UID:  eaa2304c-ca2e-4e95-a4a0-23809b39bdda\n",
    "client.set.default_space(space_uid)\n",
    "'SUCCESS'\n",
    "client.software_specifications.list()\n",
    "-----------------------------  ------------------------------------  ----\n",
    "NAME                           ASSET_ID                              TYPE\n",
    "default_py3.6                  0062b8c9-8b7d-44a0-a9b9-46c416adcbd9  base\n",
    "kernel-spark3.2-scala2.12      020d69ce-7ac1-5e68-ac1a-31189867356a  base\n",
    "pytorch-onnx_1.3-py3.7-edt     069ea134-3346-5748-b513-49120e15d288  base\n",
    "scikit-learn_0.20-py3.6        09c5a1d0-9c1e-4473-a344-eb7b665ff687  base\n",
    "spark-mllib_3.0-scala_2.12     09f4cff0-90a7-5899-b9ed-1ef348aebdee  base\n",
    "pytorch-onnx_rt22.1-py3.9      0b848dd4-e681-5599-be41-b5f6fccc6471  base\n",
    "ai-function_0.1-py3.6          0cdb0f1e-5376-4f4d-92dd-da3b69aa9bda  base\n",
    "shiny-r3.6                     0e6e79df-875e-4f24-8ae9-62dcc2148306  base\n",
    "tensorflow_2.4-py3.7-horovod   1092590a-307d-563d-9b62-4eb7d64b3f22  base\n",
    "pytorch_1.1-py3.6              10ac12d6-6b30-4ccd-8392-3e922c096a92  base\n",
    "tensorflow_1.15-py3.6-ddl      111e41b3-de2d-5422-a4d6-bf776828c4b7  base\n",
    "autoai-kb_rt22.2-py3.10        125b6d9a-5b1f-5e8d-972a-b251688ccf40  base\n",
    "runtime-22.1-py3.9             12b83a17-24d8-5082-900f-0ab31fbfd3cb  base\n",
    "scikit-learn_0.22-py3.6        154010fa-5b3b-4ac1-82af-4d5ee5abbc85  base\n",
    "default_r3.6                   1b70aec3-ab34-4b87-8aa0-a4a3c8296a36  base\n",
    "pytorch-onnx_1.3-py3.6         1bc6029a-cc97-56da-b8e0-39c3880dbbe7  base\n",
    "kernel-spark3.3-r3.6           1c9e5454-f216-59dd-a20e-474a5cdf5988  base\n",
    "pytorch-onnx_rt22.1-py3.9-edt  1d362186-7ad5-5b59-8b6c-9d0880bde37f  base\n",
    "tensorflow_2.1-py3.6           1eb25b84-d6ed-5dde-b6a5-3fbdf1665666  base\n",
    "spark-mllib_3.2                20047f72-0a98-58c7-9ff5-a77b012eb8f5  base\n",
    "tensorflow_2.4-py3.8-horovod   217c16f6-178f-56bf-824a-b19f20564c49  base\n",
    "runtime-22.1-py3.9-cuda        26215f05-08c3-5a41-a1b0-da66306ce658  base\n",
    "do_py3.8                       295addb5-9ef9-547e-9bf4-92ae3563e720  base\n",
    "autoai-ts_3.8-py3.8            2aa0c932-798f-5ae9-abd6-15e0c2402fb5  base\n",
    "tensorflow_1.15-py3.6          2b73a275-7cbf-420b-a912-eae7f436e0bc  base\n",
    "kernel-spark3.3-py3.9          2b7961e2-e3b1-5a8c-a491-482c8368839a  base\n",
    "pytorch_1.2-py3.6              2c8ef57d-2687-4b7d-acce-01f94976dac1  base\n",
    "spark-mllib_2.3                2e51f700-bca0-4b0d-88dc-5c6791338875  base\n",
    "pytorch-onnx_1.1-py3.6-edt     32983cea-3f32-4400-8965-dde874a8d67e  base\n",
    "spark-mllib_3.0-py37           36507ebe-8770-55ba-ab2a-eafe787600e9  base\n",
    "spark-mllib_2.4                390d21f8-e58b-4fac-9c55-d7ceda621326  base\n",
    "autoai-ts_rt22.2-py3.10        396b2e83-0953-5b86-9a55-7ce1628a406f  base\n",
    "xgboost_0.82-py3.6             39e31acd-5f30-41dc-ae44-60233c80306e  base\n",
    "pytorch-onnx_1.2-py3.6-edt     40589d0e-7019-4e28-8daa-fb03b6f4fe12  base\n",
    "pytorch-onnx_rt22.2-py3.10     40e73f55-783a-5535-b3fa-0c8b94291431  base\n",
    "default_r36py38                41c247d3-45f8-5a71-b065-8580229facf0  base\n",
    "autoai-ts_rt22.1-py3.9         4269d26e-07ba-5d40-8f66-2d495b0c71f7  base\n",
    "autoai-obm_3.0                 42b92e18-d9ab-567f-988a-4240ba1ed5f7  base\n",
    "pmml-3.0_4.3                   493bcb95-16f1-5bc5-bee8-81b8af80e9c7  base\n",
    "spark-mllib_2.4-r_3.6          49403dff-92e9-4c87-a3d7-a42d0021c095  base\n",
    "xgboost_0.90-py3.6             4ff8d6c2-1343-4c18-85e1-689c965304d3  base\n",
    "pytorch-onnx_1.1-py3.6         50f95b2a-bc16-43bb-bc94-b0bed208c60b  base\n",
    "autoai-ts_3.9-py3.8            52c57136-80fa-572e-8728-a5e7cbb42cde  base\n",
    "spark-mllib_2.4-scala_2.11     55a70f99-7320-4be5-9fb9-9edb5a443af5  base\n",
    "spark-mllib_3.0                5c1b0ca2-4977-5c2e-9439-ffd44ea8ffe9  base\n",
    "autoai-obm_2.0                 5c2e37fa-80b8-5e77-840f-d912469614ee  base\n",
    "spss-modeler_18.1              5c3cad7e-507f-4b2a-a9a3-ab53a21dee8b  base\n",
    "cuda-py3.8                     5d3232bf-c86b-5df4-a2cd-7bb870a1cd4e  base\n",
    "autoai-kb_3.1-py3.7            632d4b22-10aa-5180-88f0-f52dfb6444d7  base\n",
    "pytorch-onnx_1.7-py3.8         634d3cdc-b562-5bf9-a2d4-ea90a478456b  base\n",
    "-----------------------------  ------------------------------------  ----\n",
    "Note: Only first 50 records were displayed. To display more use 'limit' parameter.\n",
    "software_spec_uid = client.software_specifications.get_uid_by_name(\"runtime-22.1-py3.9\")\n",
    "software_spec_uid\n",
    "'12b83a17-24d8-5082-900f-0ab31fbfd3cb'\n",
    "model_details = client.repository.store_model(model=\"disaster.tgz\", meta_props={\n",
    "    client.repository.ModelMetaNames.NAME: \"CNN\",\n",
    "    client.repository.ModelMetaNames.TYPE: \"tensorflow_2.7\",\n",
    "    client.repository.ModelMetaNames.SOFTWARE_SPEC_UID: software_spec_uid\n",
    "})\n",
    "\n",
    "model_id = client.repository.get_model_id(model_details)\n",
    "model_id\n",
    "'19b34bdf-1aaa-4638-97e9-b2fc0d3231cf'\n",
    "client.repository.download(model_id, \"my_model.tar.gz\")\n",
    "Successfully saved model content to file: 'my_model.tar.gz'\n",
    "'/home/wsuser/work/my_model.tar.gz'\n",
    " pwd\n",
    "'/home/wsuser/work'\n",
    "import numpy as np\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Flatten, Conv2D, MaxPooling2D\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "import os, types\n",
    "import pandas as pd\n",
    "from botocore.client import Config\n",
    "import ibm_boto3\n",
    "\n",
    "def __iter__(self): return 0\n",
    "\n",
    "# @hidden_cell\n",
    "# The following code accesses a file in your IBM Cloud Object Storage. It includes your credentials.\n",
    "# You might want to remove those credentials before you share the notebook.\n",
    "cos_client = ibm_boto3.client(service_name='s3',\n",
    "    ibm_api_key_id='eqRr_BuHHp9Di6TVmW-MGXHyPXtsbYlsKBxJDrYcV7Yn',\n",
    "    ibm_auth_endpoint=\"https://iam.cloud.ibm.com/oidc/token\",\n",
    "    config=Config(signature_version='oauth'),\n",
    "    endpoint_url='https://s3.private.us.cloud-object-storage.appdomain.cloud')\n",
    "\n",
    "bucket = 'naturaldisastersintensityanalysis-donotdelete-pr-wij7ez8jjgzubp'\n",
    "object_key = 'dataset.zip'\n",
    "\n",
    "streaming_body_2 = cos_client.get_object(Bucket=bucket, Key=object_key)['Body']\n",
    "\n",
    "# Your data file was loaded into a botocore.response.StreamingBody object.\n",
    "# Please read the documentation of ibm_boto3 and pandas to learn more about the possibilities to load the data.\n",
    "# ibm_boto3 documentation: https://ibm.github.io/ibm-cos-sdk-python/\n",
    "# pandas documentation: http://pandas.pydata.org/\n",
    "from io import BytesIO\n",
    "import zipfile\n",
    "unzip = zipfile.ZipFile(BytesIO(streaming_body_2.read()),'r')\n",
    "file_paths = unzip.namelist()\n",
    "for path in file_paths:\n",
    "    unzip.extract(path)\n",
    "data_path = '/home/wsuser/work/Dataset/'\n",
    "batch_size = 32\n",
    "target_size = (64, 64)\n",
    "train_datagen = ImageDataGenerator(rescale=1./255,\n",
    "                                   shear_range=0.2,\n",
    "                                   zoom_range=0.2,\n",
    "                                   width_shift_range=0.1,\n",
    "                                   height_shift_range=0.1,\n",
    "                                   horizontal_flip=True,\n",
    "                                   validation_split=0.2)\n",
    "\n",
    "test_datagen = ImageDataGenerator(rescale=1. / 255, validation_split=0.2)\n",
    "X_train = train_datagen.flow_from_directory('/home/wsuser/work/dataset/train_set',\n",
    "                                            target_size=(64, 64),\n",
    "                                            batch_size=32,\n",
    "                                            color_mode=\"rgb\",\n",
    "                                            subset=\"training\",\n",
    "                                            class_mode='categorical')\n",
    "\n",
    "\n",
    "\n",
    "X_test = test_datagen.flow_from_directory('/home/wsuser/work/dataset/test_set',\n",
    "                                          target_size=(64, 64),\n",
    "                                          batch_size=32,\n",
    "                                          color_mode=\"rgb\",\n",
    "                                          subset=\"validation\",\n",
    "                                          class_mode='categorical')\n",
    "Found 595 images belonging to 4 classes.\n",
    "Found 37 images belonging to 4 classes.\n",
    "model = Sequential()\n",
    "model.add(Conv2D(32, (3, 3), input_shape=(64, 64, 3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Conv2D(32, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Flatten())\n",
    "\n",
    "model.add(Dense(units=128, activation='relu'))\n",
    "model.add(Dense(units=4, activation='softmax'))\n",
    "model.summary()\n",
    "Model: \"sequential\"\n",
    "_________________________________________________________________\n",
    " Layer (type)                Output Shape              Param #   \n",
    "=================================================================\n",
    " conv2d (Conv2D)             (None, 62, 62, 32)        896       \n",
    "                                                                 \n",
    " max_pooling2d (MaxPooling2D  (None, 31, 31, 32)       0         \n",
    " )                                                               \n",
    "                                                                 \n",
    " conv2d_1 (Conv2D)           (None, 29, 29, 32)        9248      \n",
    "                                                                 \n",
    " max_pooling2d_1 (MaxPooling  (None, 14, 14, 32)       0         \n",
    " 2D)                                                             \n",
    "                                                                 \n",
    " flatten (Flatten)           (None, 6272)              0         \n",
    "                                                                 \n",
    " dense (Dense)               (None, 128)               802944    \n",
    "                                                                 \n",
    " dense_1 (Dense)             (None, 4)                 516       \n",
    "                                                                 \n",
    "=================================================================\n",
    "Total params: 813,604\n",
    "Trainable params: 813,604\n",
    "Non-trainable params: 0\n",
    "_________________________________________________________________\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "model.fit(X_train, \n",
    "          steps_per_epoch=len(X_train), \n",
    "          epochs=20,\n",
    "          validation_data=X_test,\n",
    "          validation_steps=len(X_test))\n",
    "Epoch 1/20\n",
    "19/19 [==============================] - 28s 1s/step - loss: 1.2825 - accuracy: 0.4017 - val_loss: 1.1511 - val_accuracy: 0.5946\n",
    "Epoch 2/20\n",
    "19/19 [==============================] - 25s 1s/step - loss: 1.0187 - accuracy: 0.5933 - val_loss: 0.9829 - val_accuracy: 0.6757\n",
    "Epoch 3/20\n",
    "19/19 [==============================] - 25s 1s/step - loss: 0.8670 - accuracy: 0.6571 - val_loss: 1.2125 - val_accuracy: 0.4865\n",
    "Epoch 4/20\n",
    "19/19 [==============================] - 26s 1s/step - loss: 0.8239 - accuracy: 0.6723 - val_loss: 0.9556 - val_accuracy: 0.6757\n",
    "Epoch 5/20\n",
    "19/19 [==============================] - 25s 1s/step - loss: 0.7818 - accuracy: 0.6840 - val_loss: 1.0185 - val_accuracy: 0.6757\n",
    "Epoch 6/20\n",
    "19/19 [==============================] - 26s 1s/step - loss: 0.6352 - accuracy: 0.7714 - val_loss: 0.9754 - val_accuracy: 0.7568\n",
    "Epoch 7/20\n",
    "19/19 [==============================] - 26s 1s/step - loss: 0.5867 - accuracy: 0.7681 - val_loss: 0.8624 - val_accuracy: 0.7568\n",
    "Epoch 8/20\n",
    "19/19 [==============================] - 25s 1s/step - loss: 0.6245 - accuracy: 0.7681 - val_loss: 0.8863 - val_accuracy: 0.7027\n",
    "Epoch 9/20\n",
    "19/19 [==============================] - 25s 1s/step - loss: 0.6180 - accuracy: 0.7664 - val_loss: 1.5044 - val_accuracy: 0.6757\n",
    "Epoch 10/20\n",
    "19/19 [==============================] - 25s 1s/step - loss: 0.5976 - accuracy: 0.7765 - val_loss: 1.0201 - val_accuracy: 0.6757\n",
    "Epoch 11/20\n",
    "19/19 [==============================] - 25s 1s/step - loss: 0.5209 - accuracy: 0.8050 - val_loss: 0.8570 - val_accuracy: 0.7027\n",
    "Epoch 12/20\n",
    "19/19 [==============================] - 25s 1s/step - loss: 0.5374 - accuracy: 0.7899 - val_loss: 1.0046 - val_accuracy: 0.7297\n",
    "Epoch 13/20\n",
    "19/19 [==============================] - 25s 1s/step - loss: 0.5231 - accuracy: 0.7983 - val_loss: 0.8088 - val_accuracy: 0.7568\n",
    "Epoch 14/20\n",
    "19/19 [==============================] - 25s 1s/step - loss: 0.4615 - accuracy: 0.8303 - val_loss: 0.8695 - val_accuracy: 0.7568\n",
    "Epoch 15/20\n",
    "19/19 [==============================] - 26s 1s/step - loss: 0.4904 - accuracy: 0.8134 - val_loss: 1.0314 - val_accuracy: 0.7568\n",
    "Epoch 16/20\n",
    "19/19 [==============================] - 26s 1s/step - loss: 0.4355 - accuracy: 0.8286 - val_loss: 0.9395 - val_accuracy: 0.7568\n",
    "Epoch 17/20\n",
    "19/19 [==============================] - 25s 1s/step - loss: 0.4891 - accuracy: 0.8185 - val_loss: 0.9327 - val_accuracy: 0.7838\n",
    "Epoch 18/20\n",
    "19/19 [==============================] - 26s 1s/step - loss: 0.3950 - accuracy: 0.8487 - val_loss: 1.0022 - val_accuracy: 0.7568\n",
    "Epoch 19/20\n",
    "19/19 [==============================] - 25s 1s/step - loss: 0.4382 - accuracy: 0.8370 - val_loss: 0.9419 - val_accuracy: 0.8378\n",
    "Epoch 20/20\n",
    "19/19 [==============================] - 25s 1s/step - loss: 0.3950 - accuracy: 0.8387 - val_loss: 1.1659 - val_accuracy: 0.7297\n",
    "model.save(\"disaster.h5\")\n",
    "!tar -zcvf disaster.tgz disaster.h5\n",
    "disaster.h5\n",
    "ls\n",
    "dataset/  disaster.h5  disaster.tgz\n",
    "!pip install watson-machine-learning-client\n",
    "Collecting watson-machine-learning-client\n",
    "  Downloading watson_machine_learning_client-1.0.391-py3-none-any.whl (538 kB)\n",
    "     |████████████████████████████████| 538 kB 12.9 MB/s eta 0:00:01\n",
    "Requirement already satisfied: tqdm in /opt/conda/envs/Python-3.9/lib/python3.9/site-packages (from watson-machine-learning-client) (4.62.3)\n",
    "Requirement already satisfied: requests in /opt/conda/envs/Python-3.9/lib/python3.9/site-packages (from watson-machine-learning-client) (2.26.0)\n",
    "Requirement already satisfied: pandas in /opt/conda/envs/Python-3.9/lib/python3.9/site-packages (from watson-machine-learning-client) (1.3.4)\n",
    "Requirement already satisfied: urllib3 in /opt/conda/envs/Python-3.9/lib/python3.9/site-packages (from watson-machine-learning-client) (1.26.7)\n",
    "Requirement already satisfied: ibm-cos-sdk in /opt/conda/envs/Python-3.9/lib/python3.9/site-packages (from watson-machine-learning-client) (2.11.0)\n",
    "Requirement already satisfied: boto3 in /opt/conda/envs/Python-3.9/lib/python3.9/site-packages (from watson-machine-learning-client) (1.18.21)\n",
    "Requirement already satisfied: lomond in /opt/conda/envs/Python-3.9/lib/python3.9/site-packages (from watson-machine-learning-client) (0.3.3)\n",
    "Requirement already satisfied: tabulate in /opt/conda/envs/Python-3.9/lib/python3.9/site-packages (from watson-machine-learning-client) (0.8.9)\n",
    "Requirement already satisfied: certifi in /opt/conda/envs/Python-3.9/lib/python3.9/site-packages (from watson-machine-learning-client) (2022.9.24)\n",
    "Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in /opt/conda/envs/Python-3.9/lib/python3.9/site-packages (from boto3->watson-machine-learning-client) (0.10.0)\n",
    "Requirement already satisfied: botocore<1.22.0,>=1.21.21 in /opt/conda/envs/Python-3.9/lib/python3.9/site-packages (from boto3->watson-machine-learning-client) (1.21.41)\n",
    "Requirement already satisfied: s3transfer<0.6.0,>=0.5.0 in /opt/conda/envs/Python-3.9/lib/python3.9/site-packages (from boto3->watson-machine-learning-client) (0.5.0)\n",
    "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /opt/conda/envs/Python-3.9/lib/python3.9/site-packages (from botocore<1.22.0,>=1.21.21->boto3->watson-machine-learning-client) (2.8.2)\n",
    "Requirement already satisfied: six>=1.5 in /opt/conda/envs/Python-3.9/lib/python3.9/site-packages (from python-dateutil<3.0.0,>=2.1->botocore<1.22.0,>=1.21.21->boto3->watson-machine-learning-client) (1.15.0)\n",
    "Requirement already satisfied: ibm-cos-sdk-s3transfer==2.11.0 in /opt/conda/envs/Python-3.9/lib/python3.9/site-packages (from ibm-cos-sdk->watson-machine-learning-client) (2.11.0)\n",
    "Requirement already satisfied: ibm-cos-sdk-core==2.11.0 in /opt/conda/envs/Python-3.9/lib/python3.9/site-packages (from ibm-cos-sdk->watson-machine-learning-client) (2.11.0)\n",
    "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/envs/Python-3.9/lib/python3.9/site-packages (from requests->watson-machine-learning-client) (3.3)\n",
    "Requirement already satisfied: charset-normalizer~=2.0.0 in /opt/conda/envs/Python-3.9/lib/python3.9/site-packages (from requests->watson-machine-learning-client) (2.0.4)\n",
    "Requirement already satisfied: pytz>=2017.3 in /opt/conda/envs/Python-3.9/lib/python3.9/site-packages (from pandas->watson-machine-learning-client) (2021.3)\n",
    "Requirement already satisfied: numpy>=1.17.3 in /opt/conda/envs/Python-3.9/lib/python3.9/site-packages (from pandas->watson-machine-learning-client) (1.20.3)\n",
    "Installing collected packages: watson-machine-learning-client\n",
    "Successfully installed watson-machine-learning-client-1.0.391\n",
    "from ibm_watson_machine_learning import APIClient\n",
    "\n",
    "API_KEY = \"dI8836cei5gsTnRg5IXx2Jla_HxwNj1-FyYdDTq1oHkV\"\n",
    "\n",
    "wml_credentials = {\n",
    "    \"url\": \"https://us-south.ml.cloud.ibm.com\",\n",
    "    \"apikey\": API_KEY\n",
    "}\n",
    "\n",
    "client = APIClient(wml_credentials)\n",
    "client=APIClient(wml_credentials)\n",
    "def guid_from_space_name(client, space_name):\n",
    "    space = client.spaces.get_details()\n",
    "    return(next(item for item in space['resources'] if item['entity']['name'] == space_name)['metadata']['id'])\n",
    "space_uid = guid_from_space_name(client, 'Natural Disasters Intensity Analysis')\n",
    "print(\"Space UID: \", space_uid)\n",
    "Space UID:  eaa2304c-ca2e-4e95-a4a0-23809b39bdda\n",
    "client.set.default_space(space_uid)\n",
    "'SUCCESS'\n",
    "client.software_specifications.list()\n",
    "-----------------------------  ------------------------------------  ----\n",
    "NAME                           ASSET_ID                              TYPE\n",
    "default_py3.6                  0062b8c9-8b7d-44a0-a9b9-46c416adcbd9  base\n",
    "kernel-spark3.2-scala2.12      020d69ce-7ac1-5e68-ac1a-31189867356a  base\n",
    "pytorch-onnx_1.3-py3.7-edt     069ea134-3346-5748-b513-49120e15d288  base\n",
    "scikit-learn_0.20-py3.6        09c5a1d0-9c1e-4473-a344-eb7b665ff687  base\n",
    "spark-mllib_3.0-scala_2.12     09f4cff0-90a7-5899-b9ed-1ef348aebdee  base\n",
    "pytorch-onnx_rt22.1-py3.9      0b848dd4-e681-5599-be41-b5f6fccc6471  base\n",
    "ai-function_0.1-py3.6          0cdb0f1e-5376-4f4d-92dd-da3b69aa9bda  base\n",
    "shiny-r3.6                     0e6e79df-875e-4f24-8ae9-62dcc2148306  base\n",
    "tensorflow_2.4-py3.7-horovod   1092590a-307d-563d-9b62-4eb7d64b3f22  base\n",
    "pytorch_1.1-py3.6              10ac12d6-6b30-4ccd-8392-3e922c096a92  base\n",
    "tensorflow_1.15-py3.6-ddl      111e41b3-de2d-5422-a4d6-bf776828c4b7  base\n",
    "autoai-kb_rt22.2-py3.10        125b6d9a-5b1f-5e8d-972a-b251688ccf40  base\n",
    "runtime-22.1-py3.9             12b83a17-24d8-5082-900f-0ab31fbfd3cb  base\n",
    "scikit-learn_0.22-py3.6        154010fa-5b3b-4ac1-82af-4d5ee5abbc85  base\n",
    "default_r3.6                   1b70aec3-ab34-4b87-8aa0-a4a3c8296a36  base\n",
    "pytorch-onnx_1.3-py3.6         1bc6029a-cc97-56da-b8e0-39c3880dbbe7  base\n",
    "kernel-spark3.3-r3.6           1c9e5454-f216-59dd-a20e-474a5cdf5988  base\n",
    "pytorch-onnx_rt22.1-py3.9-edt  1d362186-7ad5-5b59-8b6c-9d0880bde37f  base\n",
    "tensorflow_2.1-py3.6           1eb25b84-d6ed-5dde-b6a5-3fbdf1665666  base\n",
    "spark-mllib_3.2                20047f72-0a98-58c7-9ff5-a77b012eb8f5  base\n",
    "tensorflow_2.4-py3.8-horovod   217c16f6-178f-56bf-824a-b19f20564c49  base\n",
    "runtime-22.1-py3.9-cuda        26215f05-08c3-5a41-a1b0-da66306ce658  base\n",
    "do_py3.8                       295addb5-9ef9-547e-9bf4-92ae3563e720  base\n",
    "autoai-ts_3.8-py3.8            2aa0c932-798f-5ae9-abd6-15e0c2402fb5  base\n",
    "tensorflow_1.15-py3.6          2b73a275-7cbf-420b-a912-eae7f436e0bc  base\n",
    "kernel-spark3.3-py3.9          2b7961e2-e3b1-5a8c-a491-482c8368839a  base\n",
    "pytorch_1.2-py3.6              2c8ef57d-2687-4b7d-acce-01f94976dac1  base\n",
    "spark-mllib_2.3                2e51f700-bca0-4b0d-88dc-5c6791338875  base\n",
    "pytorch-onnx_1.1-py3.6-edt     32983cea-3f32-4400-8965-dde874a8d67e  base\n",
    "spark-mllib_3.0-py37           36507ebe-8770-55ba-ab2a-eafe787600e9  base\n",
    "spark-mllib_2.4                390d21f8-e58b-4fac-9c55-d7ceda621326  base\n",
    "autoai-ts_rt22.2-py3.10        396b2e83-0953-5b86-9a55-7ce1628a406f  base\n",
    "xgboost_0.82-py3.6             39e31acd-5f30-41dc-ae44-60233c80306e  base\n",
    "pytorch-onnx_1.2-py3.6-edt     40589d0e-7019-4e28-8daa-fb03b6f4fe12  base\n",
    "pytorch-onnx_rt22.2-py3.10     40e73f55-783a-5535-b3fa-0c8b94291431  base\n",
    "default_r36py38                41c247d3-45f8-5a71-b065-8580229facf0  base\n",
    "autoai-ts_rt22.1-py3.9         4269d26e-07ba-5d40-8f66-2d495b0c71f7  base\n",
    "autoai-obm_3.0                 42b92e18-d9ab-567f-988a-4240ba1ed5f7  base\n",
    "pmml-3.0_4.3                   493bcb95-16f1-5bc5-bee8-81b8af80e9c7  base\n",
    "spark-mllib_2.4-r_3.6          49403dff-92e9-4c87-a3d7-a42d0021c095  base\n",
    "xgboost_0.90-py3.6             4ff8d6c2-1343-4c18-85e1-689c965304d3  base\n",
    "pytorch-onnx_1.1-py3.6         50f95b2a-bc16-43bb-bc94-b0bed208c60b  base\n",
    "autoai-ts_3.9-py3.8            52c57136-80fa-572e-8728-a5e7cbb42cde  base\n",
    "spark-mllib_2.4-scala_2.11     55a70f99-7320-4be5-9fb9-9edb5a443af5  base\n",
    "spark-mllib_3.0                5c1b0ca2-4977-5c2e-9439-ffd44ea8ffe9  base\n",
    "autoai-obm_2.0                 5c2e37fa-80b8-5e77-840f-d912469614ee  base\n",
    "spss-modeler_18.1              5c3cad7e-507f-4b2a-a9a3-ab53a21dee8b  base\n",
    "cuda-py3.8                     5d3232bf-c86b-5df4-a2cd-7bb870a1cd4e  base\n",
    "autoai-kb_3.1-py3.7            632d4b22-10aa-5180-88f0-f52dfb6444d7  base\n",
    "pytorch-onnx_1.7-py3.8         634d3cdc-b562-5bf9-a2d4-ea90a478456b  base\n",
    "-----------------------------  ------------------------------------  ----\n",
    "Note: Only first 50 records were displayed. To display more use 'limit' parameter.\n",
    "software_spec_uid = client.software_specifications.get_uid_by_name(\"runtime-22.1-py3.9\")\n",
    "software_spec_uid\n",
    "'12b83a17-24d8-5082-900f-0ab31fbfd3cb'\n",
    "model_details = client.repository.store_model(model=\"disaster.tgz\", meta_props={\n",
    "    client.repository.ModelMetaNames.NAME: \"CNN\",\n",
    "    client.repository.ModelMetaNames.TYPE: \"tensorflow_2.7\",\n",
    "    client.repository.ModelMetaNames.SOFTWARE_SPEC_UID: software_spec_uid\n",
    "})\n",
    "\n",
    "model_id = client.repository.get_model_id(model_details)\n",
    "model_id\n",
    "'19b34bdf-1aaa-4638-97e9-b2fc0d3231cf'\n",
    "client.repository.download(model_id, \"my_model.tar.gz\")\n",
    "Successfully saved model content to file: 'my_model.tar.gz'\n",
    "'/home/wsuser/work/my_model.tar.gz'\n",
    " pwd\n",
    "'/home/wsuser/work'\n",
    "import numpy as np\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Flatten, Conv2D, MaxPooling2D\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "import os, types\n",
    "import pandas as pd\n",
    "from botocore.client import Config\n",
    "import ibm_boto3\n",
    "\n",
    "def __iter__(self): return 0\n",
    "\n",
    "# @hidden_cell\n",
    "# The following code accesses a file in your IBM Cloud Object Storage. It includes your credentials.\n",
    "# You might want to remove those credentials before you share the notebook.\n",
    "cos_client = ibm_boto3.client(service_name='s3',\n",
    "    ibm_api_key_id='eqRr_BuHHp9Di6TVmW-MGXHyPXtsbYlsKBxJDrYcV7Yn',\n",
    "    ibm_auth_endpoint=\"https://iam.cloud.ibm.com/oidc/token\",\n",
    "    config=Config(signature_version='oauth'),\n",
    "    endpoint_url='https://s3.private.us.cloud-object-storage.appdomain.cloud')\n",
    "\n",
    "bucket = 'naturaldisastersintensityanalysis-donotdelete-pr-wij7ez8jjgzubp'\n",
    "object_key = 'dataset.zip'\n",
    "\n",
    "streaming_body_2 = cos_client.get_object(Bucket=bucket, Key=object_key)['Body']\n",
    "\n",
    "# Your data file was loaded into a botocore.response.StreamingBody object.\n",
    "# Please read the documentation of ibm_boto3 and pandas to learn more about the possibilities to load the data.\n",
    "# ibm_boto3 documentation: https://ibm.github.io/ibm-cos-sdk-python/\n",
    "# pandas documentation: http://pandas.pydata.org/\n",
    "from io import BytesIO\n",
    "import zipfile\n",
    "unzip = zipfile.ZipFile(BytesIO(streaming_body_2.read()),'r')\n",
    "file_paths = unzip.namelist()\n",
    "for path in file_paths:\n",
    "    unzip.extract(path)\n",
    "data_path = '/home/wsuser/work/Dataset/'\n",
    "batch_size = 32\n",
    "target_size = (64, 64)\n",
    "train_datagen = ImageDataGenerator(rescale=1./255,\n",
    "                                   shear_range=0.2,\n",
    "                                   zoom_range=0.2,\n",
    "                                   width_shift_range=0.1,\n",
    "                                   height_shift_range=0.1,\n",
    "                                   horizontal_flip=True,\n",
    "                                   validation_split=0.2)\n",
    "\n",
    "test_datagen = ImageDataGenerator(rescale=1. / 255, validation_split=0.2)\n",
    "X_train = train_datagen.flow_from_directory('/home/wsuser/work/dataset/train_set',\n",
    "                                            target_size=(64, 64),\n",
    "                                            batch_size=32,\n",
    "                                            color_mode=\"rgb\",\n",
    "                                            subset=\"training\",\n",
    "                                            class_mode='categorical')\n",
    "\n",
    "\n",
    "\n",
    "X_test = test_datagen.flow_from_directory('/home/wsuser/work/dataset/test_set',\n",
    "                                          target_size=(64, 64),\n",
    "                                          batch_size=32,\n",
    "                                          color_mode=\"rgb\",\n",
    "                                          subset=\"validation\",\n",
    "                                          class_mode='categorical')\n",
    "Found 595 images belonging to 4 classes.\n",
    "Found 37 images belonging to 4 classes.\n",
    "model = Sequential()\n",
    "model.add(Conv2D(32, (3, 3), input_shape=(64, 64, 3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Conv2D(32, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Flatten())\n",
    "\n",
    "model.add(Dense(units=128, activation='relu'))\n",
    "model.add(Dense(units=4, activation='softmax'))\n",
    "model.summary()\n",
    "Model: \"sequential\"\n",
    "_________________________________________________________________\n",
    " Layer (type)                Output Shape              Param #   \n",
    "=================================================================\n",
    " conv2d (Conv2D)             (None, 62, 62, 32)        896       \n",
    "                                                                 \n",
    " max_pooling2d (MaxPooling2D  (None, 31, 31, 32)       0         \n",
    " )                                                               \n",
    "                                                                 \n",
    " conv2d_1 (Conv2D)           (None, 29, 29, 32)        9248      \n",
    "                                                                 \n",
    " max_pooling2d_1 (MaxPooling  (None, 14, 14, 32)       0         \n",
    " 2D)                                                             \n",
    "                                                                 \n",
    " flatten (Flatten)           (None, 6272)              0         \n",
    "                                                                 \n",
    " dense (Dense)               (None, 128)               802944    \n",
    "                                                                 \n",
    " dense_1 (Dense)             (None, 4)                 516       \n",
    "                                                                 \n",
    "=================================================================\n",
    "Total params: 813,604\n",
    "Trainable params: 813,604\n",
    "Non-trainable params: 0\n",
    "_________________________________________________________________\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "model.fit(X_train, \n",
    "          steps_per_epoch=len(X_train), \n",
    "          epochs=20,\n",
    "          validation_data=X_test,\n",
    "          validation_steps=len(X_test))\n",
    "Epoch 1/20\n",
    "19/19 [==============================] - 28s 1s/step - loss: 1.2825 - accuracy: 0.4017 - val_loss: 1.1511 - val_accuracy: 0.5946\n",
    "Epoch 2/20\n",
    "19/19 [==============================] - 25s 1s/step - loss: 1.0187 - accuracy: 0.5933 - val_loss: 0.9829 - val_accuracy: 0.6757\n",
    "Epoch 3/20\n",
    "19/19 [==============================] - 25s 1s/step - loss: 0.8670 - accuracy: 0.6571 - val_loss: 1.2125 - val_accuracy: 0.4865\n",
    "Epoch 4/20\n",
    "19/19 [==============================] - 26s 1s/step - loss: 0.8239 - accuracy: 0.6723 - val_loss: 0.9556 - val_accuracy: 0.6757\n",
    "Epoch 5/20\n",
    "19/19 [==============================] - 25s 1s/step - loss: 0.7818 - accuracy: 0.6840 - val_loss: 1.0185 - val_accuracy: 0.6757\n",
    "Epoch 6/20\n",
    "19/19 [==============================] - 26s 1s/step - loss: 0.6352 - accuracy: 0.7714 - val_loss: 0.9754 - val_accuracy: 0.7568\n",
    "Epoch 7/20\n",
    "19/19 [==============================] - 26s 1s/step - loss: 0.5867 - accuracy: 0.7681 - val_loss: 0.8624 - val_accuracy: 0.7568\n",
    "Epoch 8/20\n",
    "19/19 [==============================] - 25s 1s/step - loss: 0.6245 - accuracy: 0.7681 - val_loss: 0.8863 - val_accuracy: 0.7027\n",
    "Epoch 9/20\n",
    "19/19 [==============================] - 25s 1s/step - loss: 0.6180 - accuracy: 0.7664 - val_loss: 1.5044 - val_accuracy: 0.6757\n",
    "Epoch 10/20\n",
    "19/19 [==============================] - 25s 1s/step - loss: 0.5976 - accuracy: 0.7765 - val_loss: 1.0201 - val_accuracy: 0.6757\n",
    "Epoch 11/20\n",
    "19/19 [==============================] - 25s 1s/step - loss: 0.5209 - accuracy: 0.8050 - val_loss: 0.8570 - val_accuracy: 0.7027\n",
    "Epoch 12/20\n",
    "19/19 [==============================] - 25s 1s/step - loss: 0.5374 - accuracy: 0.7899 - val_loss: 1.0046 - val_accuracy: 0.7297\n",
    "Epoch 13/20\n",
    "19/19 [==============================] - 25s 1s/step - loss: 0.5231 - accuracy: 0.7983 - val_loss: 0.8088 - val_accuracy: 0.7568\n",
    "Epoch 14/20\n",
    "19/19 [==============================] - 25s 1s/step - loss: 0.4615 - accuracy: 0.8303 - val_loss: 0.8695 - val_accuracy: 0.7568\n",
    "Epoch 15/20\n",
    "19/19 [==============================] - 26s 1s/step - loss: 0.4904 - accuracy: 0.8134 - val_loss: 1.0314 - val_accuracy: 0.7568\n",
    "Epoch 16/20\n",
    "19/19 [==============================] - 26s 1s/step - loss: 0.4355 - accuracy: 0.8286 - val_loss: 0.9395 - val_accuracy: 0.7568\n",
    "Epoch 17/20\n",
    "19/19 [==============================] - 25s 1s/step - loss: 0.4891 - accuracy: 0.8185 - val_loss: 0.9327 - val_accuracy: 0.7838\n",
    "Epoch 18/20\n",
    "19/19 [==============================] - 26s 1s/step - loss: 0.3950 - accuracy: 0.8487 - val_loss: 1.0022 - val_accuracy: 0.7568\n",
    "Epoch 19/20\n",
    "19/19 [==============================] - 25s 1s/step - loss: 0.4382 - accuracy: 0.8370 - val_loss: 0.9419 - val_accuracy: 0.8378\n",
    "Epoch 20/20\n",
    "19/19 [==============================] - 25s 1s/step - loss: 0.3950 - accuracy: 0.8387 - val_loss: 1.1659 - val_accuracy: 0.7297\n",
    "model.save(\"disaster.h5\")\n",
    "!tar -zcvf disaster.tgz disaster.h5\n",
    "disaster.h5\n",
    "ls\n",
    "dataset/  disaster.h5  disaster.tgz\n",
    "!pip install watson-machine-learning-client\n",
    "Collecting watson-machine-learning-client\n",
    "  Downloading watson_machine_learning_client-1.0.391-py3-none-any.whl (538 kB)\n",
    "     |████████████████████████████████| 538 kB 12.9 MB/s eta 0:00:01\n",
    "Requirement already satisfied: tqdm in /opt/conda/envs/Python-3.9/lib/python3.9/site-packages (from watson-machine-learning-client) (4.62.3)\n",
    "Requirement already satisfied: requests in /opt/conda/envs/Python-3.9/lib/python3.9/site-packages (from watson-machine-learning-client) (2.26.0)\n",
    "Requirement already satisfied: pandas in /opt/conda/envs/Python-3.9/lib/python3.9/site-packages (from watson-machine-learning-client) (1.3.4)\n",
    "Requirement already satisfied: urllib3 in /opt/conda/envs/Python-3.9/lib/python3.9/site-packages (from watson-machine-learning-client) (1.26.7)\n",
    "Requirement already satisfied: ibm-cos-sdk in /opt/conda/envs/Python-3.9/lib/python3.9/site-packages (from watson-machine-learning-client) (2.11.0)\n",
    "Requirement already satisfied: boto3 in /opt/conda/envs/Python-3.9/lib/python3.9/site-packages (from watson-machine-learning-client) (1.18.21)\n",
    "Requirement already satisfied: lomond in /opt/conda/envs/Python-3.9/lib/python3.9/site-packages (from watson-machine-learning-client) (0.3.3)\n",
    "Requirement already satisfied: tabulate in /opt/conda/envs/Python-3.9/lib/python3.9/site-packages (from watson-machine-learning-client) (0.8.9)\n",
    "Requirement already satisfied: certifi in /opt/conda/envs/Python-3.9/lib/python3.9/site-packages (from watson-machine-learning-client) (2022.9.24)\n",
    "Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in /opt/conda/envs/Python-3.9/lib/python3.9/site-packages (from boto3->watson-machine-learning-client) (0.10.0)\n",
    "Requirement already satisfied: botocore<1.22.0,>=1.21.21 in /opt/conda/envs/Python-3.9/lib/python3.9/site-packages (from boto3->watson-machine-learning-client) (1.21.41)\n",
    "Requirement already satisfied: s3transfer<0.6.0,>=0.5.0 in /opt/conda/envs/Python-3.9/lib/python3.9/site-packages (from boto3->watson-machine-learning-client) (0.5.0)\n",
    "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /opt/conda/envs/Python-3.9/lib/python3.9/site-packages (from botocore<1.22.0,>=1.21.21->boto3->watson-machine-learning-client) (2.8.2)\n",
    "Requirement already satisfied: six>=1.5 in /opt/conda/envs/Python-3.9/lib/python3.9/site-packages (from python-dateutil<3.0.0,>=2.1->botocore<1.22.0,>=1.21.21->boto3->watson-machine-learning-client) (1.15.0)\n",
    "Requirement already satisfied: ibm-cos-sdk-s3transfer==2.11.0 in /opt/conda/envs/Python-3.9/lib/python3.9/site-packages (from ibm-cos-sdk->watson-machine-learning-client) (2.11.0)\n",
    "Requirement already satisfied: ibm-cos-sdk-core==2.11.0 in /opt/conda/envs/Python-3.9/lib/python3.9/site-packages (from ibm-cos-sdk->watson-machine-learning-client) (2.11.0)\n",
    "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/envs/Python-3.9/lib/python3.9/site-packages (from requests->watson-machine-learning-client) (3.3)\n",
    "Requirement already satisfied: charset-normalizer~=2.0.0 in /opt/conda/envs/Python-3.9/lib/python3.9/site-packages (from requests->watson-machine-learning-client) (2.0.4)\n",
    "Requirement already satisfied: pytz>=2017.3 in /opt/conda/envs/Python-3.9/lib/python3.9/site-packages (from pandas->watson-machine-learning-client) (2021.3)\n",
    "Requirement already satisfied: numpy>=1.17.3 in /opt/conda/envs/Python-3.9/lib/python3.9/site-packages (from pandas->watson-machine-learning-client) (1.20.3)\n",
    "Installing collected packages: watson-machine-learning-client\n",
    "Successfully installed watson-machine-learning-client-1.0.391\n",
    "from ibm_watson_machine_learning import APIClient\n",
    "\n",
    "API_KEY = \"dI8836cei5gsTnRg5IXx2Jla_HxwNj1-FyYdDTq1oHkV\"\n",
    "\n",
    "wml_credentials = {\n",
    "    \"url\": \"https://us-south.ml.cloud.ibm.com\",\n",
    "    \"apikey\": API_KEY\n",
    "}\n",
    "\n",
    "client = APIClient(wml_credentials)\n",
    "client=APIClient(wml_credentials)\n",
    "def guid_from_space_name(client, space_name):\n",
    "    space = client.spaces.get_details()\n",
    "    return(next(item for item in space['resources'] if item['entity']['name'] == space_name)['metadata']['id'])\n",
    "space_uid = guid_from_space_name(client, 'Natural Disasters Intensity Analysis')\n",
    "print(\"Space UID: \", space_uid)\n",
    "Space UID:  eaa2304c-ca2e-4e95-a4a0-23809b39bdda\n",
    "client.set.default_space(space_uid)\n",
    "'SUCCESS'\n",
    "client.software_specifications.list()\n",
    "-----------------------------  ------------------------------------  ----\n",
    "NAME                           ASSET_ID                              TYPE\n",
    "default_py3.6                  0062b8c9-8b7d-44a0-a9b9-46c416adcbd9  base\n",
    "kernel-spark3.2-scala2.12      020d69ce-7ac1-5e68-ac1a-31189867356a  base\n",
    "pytorch-onnx_1.3-py3.7-edt     069ea134-3346-5748-b513-49120e15d288  base\n",
    "scikit-learn_0.20-py3.6        09c5a1d0-9c1e-4473-a344-eb7b665ff687  base\n",
    "spark-mllib_3.0-scala_2.12     09f4cff0-90a7-5899-b9ed-1ef348aebdee  base\n",
    "pytorch-onnx_rt22.1-py3.9      0b848dd4-e681-5599-be41-b5f6fccc6471  base\n",
    "ai-function_0.1-py3.6          0cdb0f1e-5376-4f4d-92dd-da3b69aa9bda  base\n",
    "shiny-r3.6                     0e6e79df-875e-4f24-8ae9-62dcc2148306  base\n",
    "tensorflow_2.4-py3.7-horovod   1092590a-307d-563d-9b62-4eb7d64b3f22  base\n",
    "pytorch_1.1-py3.6              10ac12d6-6b30-4ccd-8392-3e922c096a92  base\n",
    "tensorflow_1.15-py3.6-ddl      111e41b3-de2d-5422-a4d6-bf776828c4b7  base\n",
    "autoai-kb_rt22.2-py3.10        125b6d9a-5b1f-5e8d-972a-b251688ccf40  base\n",
    "runtime-22.1-py3.9             12b83a17-24d8-5082-900f-0ab31fbfd3cb  base\n",
    "scikit-learn_0.22-py3.6        154010fa-5b3b-4ac1-82af-4d5ee5abbc85  base\n",
    "default_r3.6                   1b70aec3-ab34-4b87-8aa0-a4a3c8296a36  base\n",
    "pytorch-onnx_1.3-py3.6         1bc6029a-cc97-56da-b8e0-39c3880dbbe7  base\n",
    "kernel-spark3.3-r3.6           1c9e5454-f216-59dd-a20e-474a5cdf5988  base\n",
    "pytorch-onnx_rt22.1-py3.9-edt  1d362186-7ad5-5b59-8b6c-9d0880bde37f  base\n",
    "tensorflow_2.1-py3.6           1eb25b84-d6ed-5dde-b6a5-3fbdf1665666  base\n",
    "spark-mllib_3.2                20047f72-0a98-58c7-9ff5-a77b012eb8f5  base\n",
    "tensorflow_2.4-py3.8-horovod   217c16f6-178f-56bf-824a-b19f20564c49  base\n",
    "runtime-22.1-py3.9-cuda        26215f05-08c3-5a41-a1b0-da66306ce658  base\n",
    "do_py3.8                       295addb5-9ef9-547e-9bf4-92ae3563e720  base\n",
    "autoai-ts_3.8-py3.8            2aa0c932-798f-5ae9-abd6-15e0c2402fb5  base\n",
    "tensorflow_1.15-py3.6          2b73a275-7cbf-420b-a912-eae7f436e0bc  base\n",
    "kernel-spark3.3-py3.9          2b7961e2-e3b1-5a8c-a491-482c8368839a  base\n",
    "pytorch_1.2-py3.6              2c8ef57d-2687-4b7d-acce-01f94976dac1  base\n",
    "spark-mllib_2.3                2e51f700-bca0-4b0d-88dc-5c6791338875  base\n",
    "pytorch-onnx_1.1-py3.6-edt     32983cea-3f32-4400-8965-dde874a8d67e  base\n",
    "spark-mllib_3.0-py37           36507ebe-8770-55ba-ab2a-eafe787600e9  base\n",
    "spark-mllib_2.4                390d21f8-e58b-4fac-9c55-d7ceda621326  base\n",
    "autoai-ts_rt22.2-py3.10        396b2e83-0953-5b86-9a55-7ce1628a406f  base\n",
    "xgboost_0.82-py3.6             39e31acd-5f30-41dc-ae44-60233c80306e  base\n",
    "pytorch-onnx_1.2-py3.6-edt     40589d0e-7019-4e28-8daa-fb03b6f4fe12  base\n",
    "pytorch-onnx_rt22.2-py3.10     40e73f55-783a-5535-b3fa-0c8b94291431  base\n",
    "default_r36py38                41c247d3-45f8-5a71-b065-8580229facf0  base\n",
    "autoai-ts_rt22.1-py3.9         4269d26e-07ba-5d40-8f66-2d495b0c71f7  base\n",
    "autoai-obm_3.0                 42b92e18-d9ab-567f-988a-4240ba1ed5f7  base\n",
    "pmml-3.0_4.3                   493bcb95-16f1-5bc5-bee8-81b8af80e9c7  base\n",
    "spark-mllib_2.4-r_3.6          49403dff-92e9-4c87-a3d7-a42d0021c095  base\n",
    "xgboost_0.90-py3.6             4ff8d6c2-1343-4c18-85e1-689c965304d3  base\n",
    "pytorch-onnx_1.1-py3.6         50f95b2a-bc16-43bb-bc94-b0bed208c60b  base\n",
    "autoai-ts_3.9-py3.8            52c57136-80fa-572e-8728-a5e7cbb42cde  base\n",
    "spark-mllib_2.4-scala_2.11     55a70f99-7320-4be5-9fb9-9edb5a443af5  base\n",
    "spark-mllib_3.0                5c1b0ca2-4977-5c2e-9439-ffd44ea8ffe9  base\n",
    "autoai-obm_2.0                 5c2e37fa-80b8-5e77-840f-d912469614ee  base\n",
    "spss-modeler_18.1              5c3cad7e-507f-4b2a-a9a3-ab53a21dee8b  base\n",
    "cuda-py3.8                     5d3232bf-c86b-5df4-a2cd-7bb870a1cd4e  base\n",
    "autoai-kb_3.1-py3.7            632d4b22-10aa-5180-88f0-f52dfb6444d7  base\n",
    "pytorch-onnx_1.7-py3.8         634d3cdc-b562-5bf9-a2d4-ea90a478456b  base\n",
    "-----------------------------  ------------------------------------  ----\n",
    "Note: Only first 50 records were displayed. To display more use 'limit' parameter.\n",
    "software_spec_uid = client.software_specifications.get_uid_by_name(\"runtime-22.1-py3.9\")\n",
    "software_spec_uid\n",
    "'12b83a17-24d8-5082-900f-0ab31fbfd3cb'\n",
    "model_details = client.repository.store_model(model=\"disaster.tgz\", meta_props={\n",
    "    client.repository.ModelMetaNames.NAME: \"CNN\",\n",
    "    client.repository.ModelMetaNames.TYPE: \"tensorflow_2.7\",\n",
    "    client.repository.ModelMetaNames.SOFTWARE_SPEC_UID: software_spec_uid\n",
    "})\n",
    "\n",
    "model_id = client.repository.get_model_id(model_details)\n",
    "model_id\n",
    "'19b34bdf-1aaa-4638-97e9-b2fc0d3231cf'\n",
    "client.repository.download(model_id, \"my_model.tar.gz\")\n",
    "Successfully saved model content to file: 'my_model.tar.gz'\n",
    "'/home/wsuser/work/my_model.tar.gz'\n",
    " pwd\n",
    "'/home/wsuser/work'\n",
    "import numpy as np\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Flatten, Conv2D, MaxPooling2D\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "import os, types\n",
    "import pandas as pd\n",
    "from botocore.client import Config\n",
    "import ibm_boto3\n",
    "\n",
    "def __iter__(self): return 0\n",
    "\n",
    "# @hidden_cell\n",
    "# The following code accesses a file in your IBM Cloud Object Storage. It includes your credentials.\n",
    "# You might want to remove those credentials before you share the notebook.\n",
    "cos_client = ibm_boto3.client(service_name='s3',\n",
    "    ibm_api_key_id='eqRr_BuHHp9Di6TVmW-MGXHyPXtsbYlsKBxJDrYcV7Yn',\n",
    "    ibm_auth_endpoint=\"https://iam.cloud.ibm.com/oidc/token\",\n",
    "    config=Config(signature_version='oauth'),\n",
    "    endpoint_url='https://s3.private.us.cloud-object-storage.appdomain.cloud')\n",
    "\n",
    "bucket = 'naturaldisastersintensityanalysis-donotdelete-pr-wij7ez8jjgzubp'\n",
    "object_key = 'dataset.zip'\n",
    "\n",
    "streaming_body_2 = cos_client.get_object(Bucket=bucket, Key=object_key)['Body']\n",
    "\n",
    "# Your data file was loaded into a botocore.response.StreamingBody object.\n",
    "# Please read the documentation of ibm_boto3 and pandas to learn more about the possibilities to load the data.\n",
    "# ibm_boto3 documentation: https://ibm.github.io/ibm-cos-sdk-python/\n",
    "# pandas documentation: http://pandas.pydata.org/\n",
    "from io import BytesIO\n",
    "import zipfile\n",
    "unzip = zipfile.ZipFile(BytesIO(streaming_body_2.read()),'r')\n",
    "file_paths = unzip.namelist()\n",
    "for path in file_paths:\n",
    "    unzip.extract(path)\n",
    "data_path = '/home/wsuser/work/Dataset/'\n",
    "batch_size = 32\n",
    "target_size = (64, 64)\n",
    "train_datagen = ImageDataGenerator(rescale=1./255,\n",
    "                                   shear_range=0.2,\n",
    "                                   zoom_range=0.2,\n",
    "                                   width_shift_range=0.1,\n",
    "                                   height_shift_range=0.1,\n",
    "                                   horizontal_flip=True,\n",
    "                                   validation_split=0.2)\n",
    "\n",
    "test_datagen = ImageDataGenerator(rescale=1. / 255, validation_split=0.2)\n",
    "X_train = train_datagen.flow_from_directory('/home/wsuser/work/dataset/train_set',\n",
    "                                            target_size=(64, 64),\n",
    "                                            batch_size=32,\n",
    "                                            color_mode=\"rgb\",\n",
    "                                            subset=\"training\",\n",
    "                                            class_mode='categorical')\n",
    "\n",
    "\n",
    "\n",
    "X_test = test_datagen.flow_from_directory('/home/wsuser/work/dataset/test_set',\n",
    "                                          target_size=(64, 64),\n",
    "                                          batch_size=32,\n",
    "                                          color_mode=\"rgb\",\n",
    "                                          subset=\"validation\",\n",
    "                                          class_mode='categorical')\n",
    "Found 595 images belonging to 4 classes.\n",
    "Found 37 images belonging to 4 classes.\n",
    "model = Sequential()\n",
    "model.add(Conv2D(32, (3, 3), input_shape=(64, 64, 3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Conv2D(32, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Flatten())\n",
    "\n",
    "model.add(Dense(units=128, activation='relu'))\n",
    "model.add(Dense(units=4, activation='softmax'))\n",
    "model.summary()\n",
    "Model: \"sequential\"\n",
    "_________________________________________________________________\n",
    " Layer (type)                Output Shape              Param #   \n",
    "=================================================================\n",
    " conv2d (Conv2D)             (None, 62, 62, 32)        896       \n",
    "                                                                 \n",
    " max_pooling2d (MaxPooling2D  (None, 31, 31, 32)       0         \n",
    " )                                                               \n",
    "                                                                 \n",
    " conv2d_1 (Conv2D)           (None, 29, 29, 32)        9248      \n",
    "                                                                 \n",
    " max_pooling2d_1 (MaxPooling  (None, 14, 14, 32)       0         \n",
    " 2D)                                                             \n",
    "                                                                 \n",
    " flatten (Flatten)           (None, 6272)              0         \n",
    "                                                                 \n",
    " dense (Dense)               (None, 128)               802944    \n",
    "                                                                 \n",
    " dense_1 (Dense)             (None, 4)                 516       \n",
    "                                                                 \n",
    "=================================================================\n",
    "Total params: 813,604\n",
    "Trainable params: 813,604\n",
    "Non-trainable params: 0\n",
    "_________________________________________________________________\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "model.fit(X_train, \n",
    "          steps_per_epoch=len(X_train), \n",
    "          epochs=20,\n",
    "          validation_data=X_test,\n",
    "          validation_steps=len(X_test))\n",
    "Epoch 1/20\n",
    "19/19 [==============================] - 28s 1s/step - loss: 1.2825 - accuracy: 0.4017 - val_loss: 1.1511 - val_accuracy: 0.5946\n",
    "Epoch 2/20\n",
    "19/19 [==============================] - 25s 1s/step - loss: 1.0187 - accuracy: 0.5933 - val_loss: 0.9829 - val_accuracy: 0.6757\n",
    "Epoch 3/20\n",
    "19/19 [==============================] - 25s 1s/step - loss: 0.8670 - accuracy: 0.6571 - val_loss: 1.2125 - val_accuracy: 0.4865\n",
    "Epoch 4/20\n",
    "19/19 [==============================] - 26s 1s/step - loss: 0.8239 - accuracy: 0.6723 - val_loss: 0.9556 - val_accuracy: 0.6757\n",
    "Epoch 5/20\n",
    "19/19 [==============================] - 25s 1s/step - loss: 0.7818 - accuracy: 0.6840 - val_loss: 1.0185 - val_accuracy: 0.6757\n",
    "Epoch 6/20\n",
    "19/19 [==============================] - 26s 1s/step - loss: 0.6352 - accuracy: 0.7714 - val_loss: 0.9754 - val_accuracy: 0.7568\n",
    "Epoch 7/20\n",
    "19/19 [==============================] - 26s 1s/step - loss: 0.5867 - accuracy: 0.7681 - val_loss: 0.8624 - val_accuracy: 0.7568\n",
    "Epoch 8/20\n",
    "19/19 [==============================] - 25s 1s/step - loss: 0.6245 - accuracy: 0.7681 - val_loss: 0.8863 - val_accuracy: 0.7027\n",
    "Epoch 9/20\n",
    "19/19 [==============================] - 25s 1s/step - loss: 0.6180 - accuracy: 0.7664 - val_loss: 1.5044 - val_accuracy: 0.6757\n",
    "Epoch 10/20\n",
    "19/19 [==============================] - 25s 1s/step - loss: 0.5976 - accuracy: 0.7765 - val_loss: 1.0201 - val_accuracy: 0.6757\n",
    "Epoch 11/20\n",
    "19/19 [==============================] - 25s 1s/step - loss: 0.5209 - accuracy: 0.8050 - val_loss: 0.8570 - val_accuracy: 0.7027\n",
    "Epoch 12/20\n",
    "19/19 [==============================] - 25s 1s/step - loss: 0.5374 - accuracy: 0.7899 - val_loss: 1.0046 - val_accuracy: 0.7297\n",
    "Epoch 13/20\n",
    "19/19 [==============================] - 25s 1s/step - loss: 0.5231 - accuracy: 0.7983 - val_loss: 0.8088 - val_accuracy: 0.7568\n",
    "Epoch 14/20\n",
    "19/19 [==============================] - 25s 1s/step - loss: 0.4615 - accuracy: 0.8303 - val_loss: 0.8695 - val_accuracy: 0.7568\n",
    "Epoch 15/20\n",
    "19/19 [==============================] - 26s 1s/step - loss: 0.4904 - accuracy: 0.8134 - val_loss: 1.0314 - val_accuracy: 0.7568\n",
    "Epoch 16/20\n",
    "19/19 [==============================] - 26s 1s/step - loss: 0.4355 - accuracy: 0.8286 - val_loss: 0.9395 - val_accuracy: 0.7568\n",
    "Epoch 17/20\n",
    "19/19 [==============================] - 25s 1s/step - loss: 0.4891 - accuracy: 0.8185 - val_loss: 0.9327 - val_accuracy: 0.7838\n",
    "Epoch 18/20\n",
    "19/19 [==============================] - 26s 1s/step - loss: 0.3950 - accuracy: 0.8487 - val_loss: 1.0022 - val_accuracy: 0.7568\n",
    "Epoch 19/20\n",
    "19/19 [==============================] - 25s 1s/step - loss: 0.4382 - accuracy: 0.8370 - val_loss: 0.9419 - val_accuracy: 0.8378\n",
    "Epoch 20/20\n",
    "19/19 [==============================] - 25s 1s/step - loss: 0.3950 - accuracy: 0.8387 - val_loss: 1.1659 - val_accuracy: 0.7297\n",
    "model.save(\"disaster.h5\")\n",
    "!tar -zcvf disaster.tgz disaster.h5\n",
    "disaster.h5\n",
    "ls\n",
    "dataset/  disaster.h5  disaster.tgz\n",
    "!pip install watson-machine-learning-client\n",
    "Collecting watson-machine-learning-client\n",
    "  Downloading watson_machine_learning_client-1.0.391-py3-none-any.whl (538 kB)\n",
    "     |████████████████████████████████| 538 kB 12.9 MB/s eta 0:00:01\n",
    "Requirement already satisfied: tqdm in /opt/conda/envs/Python-3.9/lib/python3.9/site-packages (from watson-machine-learning-client) (4.62.3)\n",
    "Requirement already satisfied: requests in /opt/conda/envs/Python-3.9/lib/python3.9/site-packages (from watson-machine-learning-client) (2.26.0)\n",
    "Requirement already satisfied: pandas in /opt/conda/envs/Python-3.9/lib/python3.9/site-packages (from watson-machine-learning-client) (1.3.4)\n",
    "Requirement already satisfied: urllib3 in /opt/conda/envs/Python-3.9/lib/python3.9/site-packages (from watson-machine-learning-client) (1.26.7)\n",
    "Requirement already satisfied: ibm-cos-sdk in /opt/conda/envs/Python-3.9/lib/python3.9/site-packages (from watson-machine-learning-client) (2.11.0)\n",
    "Requirement already satisfied: boto3 in /opt/conda/envs/Python-3.9/lib/python3.9/site-packages (from watson-machine-learning-client) (1.18.21)\n",
    "Requirement already satisfied: lomond in /opt/conda/envs/Python-3.9/lib/python3.9/site-packages (from watson-machine-learning-client) (0.3.3)\n",
    "Requirement already satisfied: tabulate in /opt/conda/envs/Python-3.9/lib/python3.9/site-packages (from watson-machine-learning-client) (0.8.9)\n",
    "Requirement already satisfied: certifi in /opt/conda/envs/Python-3.9/lib/python3.9/site-packages (from watson-machine-learning-client) (2022.9.24)\n",
    "Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in /opt/conda/envs/Python-3.9/lib/python3.9/site-packages (from boto3->watson-machine-learning-client) (0.10.0)\n",
    "Requirement already satisfied: botocore<1.22.0,>=1.21.21 in /opt/conda/envs/Python-3.9/lib/python3.9/site-packages (from boto3->watson-machine-learning-client) (1.21.41)\n",
    "Requirement already satisfied: s3transfer<0.6.0,>=0.5.0 in /opt/conda/envs/Python-3.9/lib/python3.9/site-packages (from boto3->watson-machine-learning-client) (0.5.0)\n",
    "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /opt/conda/envs/Python-3.9/lib/python3.9/site-packages (from botocore<1.22.0,>=1.21.21->boto3->watson-machine-learning-client) (2.8.2)\n",
    "Requirement already satisfied: six>=1.5 in /opt/conda/envs/Python-3.9/lib/python3.9/site-packages (from python-dateutil<3.0.0,>=2.1->botocore<1.22.0,>=1.21.21->boto3->watson-machine-learning-client) (1.15.0)\n",
    "Requirement already satisfied: ibm-cos-sdk-s3transfer==2.11.0 in /opt/conda/envs/Python-3.9/lib/python3.9/site-packages (from ibm-cos-sdk->watson-machine-learning-client) (2.11.0)\n",
    "Requirement already satisfied: ibm-cos-sdk-core==2.11.0 in /opt/conda/envs/Python-3.9/lib/python3.9/site-packages (from ibm-cos-sdk->watson-machine-learning-client) (2.11.0)\n",
    "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/envs/Python-3.9/lib/python3.9/site-packages (from requests->watson-machine-learning-client) (3.3)\n",
    "Requirement already satisfied: charset-normalizer~=2.0.0 in /opt/conda/envs/Python-3.9/lib/python3.9/site-packages (from requests->watson-machine-learning-client) (2.0.4)\n",
    "Requirement already satisfied: pytz>=2017.3 in /opt/conda/envs/Python-3.9/lib/python3.9/site-packages (from pandas->watson-machine-learning-client) (2021.3)\n",
    "Requirement already satisfied: numpy>=1.17.3 in /opt/conda/envs/Python-3.9/lib/python3.9/site-packages (from pandas->watson-machine-learning-client) (1.20.3)\n",
    "Installing collected packages: watson-machine-learning-client\n",
    "Successfully installed watson-machine-learning-client-1.0.391\n",
    "from ibm_watson_machine_learning import APIClient\n",
    "\n",
    "API_KEY = \"dI8836cei5gsTnRg5IXx2Jla_HxwNj1-FyYdDTq1oHkV\"\n",
    "\n",
    "wml_credentials = {\n",
    "    \"url\": \"https://us-south.ml.cloud.ibm.com\",\n",
    "    \"apikey\": API_KEY\n",
    "}\n",
    "\n",
    "client = APIClient(wml_credentials)\n",
    "client=APIClient(wml_credentials)\n",
    "def guid_from_space_name(client, space_name):\n",
    "    space = client.spaces.get_details()\n",
    "    return(next(item for item in space['resources'] if item['entity']['name'] == space_name)['metadata']['id'])\n",
    "space_uid = guid_from_space_name(client, 'Natural Disasters Intensity Analysis')\n",
    "print(\"Space UID: \", space_uid)\n",
    "Space UID:  eaa2304c-ca2e-4e95-a4a0-23809b39bdda\n",
    "client.set.default_space(space_uid)\n",
    "'SUCCESS'\n",
    "client.software_specifications.list()\n",
    "-----------------------------  ------------------------------------  ----\n",
    "NAME                           ASSET_ID                              TYPE\n",
    "default_py3.6                  0062b8c9-8b7d-44a0-a9b9-46c416adcbd9  base\n",
    "kernel-spark3.2-scala2.12      020d69ce-7ac1-5e68-ac1a-31189867356a  base\n",
    "pytorch-onnx_1.3-py3.7-edt     069ea134-3346-5748-b513-49120e15d288  base\n",
    "scikit-learn_0.20-py3.6        09c5a1d0-9c1e-4473-a344-eb7b665ff687  base\n",
    "spark-mllib_3.0-scala_2.12     09f4cff0-90a7-5899-b9ed-1ef348aebdee  base\n",
    "pytorch-onnx_rt22.1-py3.9      0b848dd4-e681-5599-be41-b5f6fccc6471  base\n",
    "ai-function_0.1-py3.6          0cdb0f1e-5376-4f4d-92dd-da3b69aa9bda  base\n",
    "shiny-r3.6                     0e6e79df-875e-4f24-8ae9-62dcc2148306  base\n",
    "tensorflow_2.4-py3.7-horovod   1092590a-307d-563d-9b62-4eb7d64b3f22  base\n",
    "pytorch_1.1-py3.6              10ac12d6-6b30-4ccd-8392-3e922c096a92  base\n",
    "tensorflow_1.15-py3.6-ddl      111e41b3-de2d-5422-a4d6-bf776828c4b7  base\n",
    "autoai-kb_rt22.2-py3.10        125b6d9a-5b1f-5e8d-972a-b251688ccf40  base\n",
    "runtime-22.1-py3.9             12b83a17-24d8-5082-900f-0ab31fbfd3cb  base\n",
    "scikit-learn_0.22-py3.6        154010fa-5b3b-4ac1-82af-4d5ee5abbc85  base\n",
    "default_r3.6                   1b70aec3-ab34-4b87-8aa0-a4a3c8296a36  base\n",
    "pytorch-onnx_1.3-py3.6         1bc6029a-cc97-56da-b8e0-39c3880dbbe7  base\n",
    "kernel-spark3.3-r3.6           1c9e5454-f216-59dd-a20e-474a5cdf5988  base\n",
    "pytorch-onnx_rt22.1-py3.9-edt  1d362186-7ad5-5b59-8b6c-9d0880bde37f  base\n",
    "tensorflow_2.1-py3.6           1eb25b84-d6ed-5dde-b6a5-3fbdf1665666  base\n",
    "spark-mllib_3.2                20047f72-0a98-58c7-9ff5-a77b012eb8f5  base\n",
    "tensorflow_2.4-py3.8-horovod   217c16f6-178f-56bf-824a-b19f20564c49  base\n",
    "runtime-22.1-py3.9-cuda        26215f05-08c3-5a41-a1b0-da66306ce658  base\n",
    "do_py3.8                       295addb5-9ef9-547e-9bf4-92ae3563e720  base\n",
    "autoai-ts_3.8-py3.8            2aa0c932-798f-5ae9-abd6-15e0c2402fb5  base\n",
    "tensorflow_1.15-py3.6          2b73a275-7cbf-420b-a912-eae7f436e0bc  base\n",
    "kernel-spark3.3-py3.9          2b7961e2-e3b1-5a8c-a491-482c8368839a  base\n",
    "pytorch_1.2-py3.6              2c8ef57d-2687-4b7d-acce-01f94976dac1  base\n",
    "spark-mllib_2.3                2e51f700-bca0-4b0d-88dc-5c6791338875  base\n",
    "pytorch-onnx_1.1-py3.6-edt     32983cea-3f32-4400-8965-dde874a8d67e  base\n",
    "spark-mllib_3.0-py37           36507ebe-8770-55ba-ab2a-eafe787600e9  base\n",
    "spark-mllib_2.4                390d21f8-e58b-4fac-9c55-d7ceda621326  base\n",
    "autoai-ts_rt22.2-py3.10        396b2e83-0953-5b86-9a55-7ce1628a406f  base\n",
    "xgboost_0.82-py3.6             39e31acd-5f30-41dc-ae44-60233c80306e  base\n",
    "pytorch-onnx_1.2-py3.6-edt     40589d0e-7019-4e28-8daa-fb03b6f4fe12  base\n",
    "pytorch-onnx_rt22.2-py3.10     40e73f55-783a-5535-b3fa-0c8b94291431  base\n",
    "default_r36py38                41c247d3-45f8-5a71-b065-8580229facf0  base\n",
    "autoai-ts_rt22.1-py3.9         4269d26e-07ba-5d40-8f66-2d495b0c71f7  base\n",
    "autoai-obm_3.0                 42b92e18-d9ab-567f-988a-4240ba1ed5f7  base\n",
    "pmml-3.0_4.3                   493bcb95-16f1-5bc5-bee8-81b8af80e9c7  base\n",
    "spark-mllib_2.4-r_3.6          49403dff-92e9-4c87-a3d7-a42d0021c095  base\n",
    "xgboost_0.90-py3.6             4ff8d6c2-1343-4c18-85e1-689c965304d3  base\n",
    "pytorch-onnx_1.1-py3.6         50f95b2a-bc16-43bb-bc94-b0bed208c60b  base\n",
    "autoai-ts_3.9-py3.8            52c57136-80fa-572e-8728-a5e7cbb42cde  base\n",
    "spark-mllib_2.4-scala_2.11     55a70f99-7320-4be5-9fb9-9edb5a443af5  base\n",
    "spark-mllib_3.0                5c1b0ca2-4977-5c2e-9439-ffd44ea8ffe9  base\n",
    "autoai-obm_2.0                 5c2e37fa-80b8-5e77-840f-d912469614ee  base\n",
    "spss-modeler_18.1              5c3cad7e-507f-4b2a-a9a3-ab53a21dee8b  base\n",
    "cuda-py3.8                     5d3232bf-c86b-5df4-a2cd-7bb870a1cd4e  base\n",
    "autoai-kb_3.1-py3.7            632d4b22-10aa-5180-88f0-f52dfb6444d7  base\n",
    "pytorch-onnx_1.7-py3.8         634d3cdc-b562-5bf9-a2d4-ea90a478456b  base\n",
    "-----------------------------  ------------------------------------  ----\n",
    "Note: Only first 50 records were displayed. To display more use 'limit' parameter.\n",
    "software_spec_uid = client.software_specifications.get_uid_by_name(\"runtime-22.1-py3.9\")\n",
    "software_spec_uid\n",
    "'12b83a17-24d8-5082-900f-0ab31fbfd3cb'\n",
    "model_details = client.repository.store_model(model=\"disaster.tgz\", meta_props={\n",
    "    client.repository.ModelMetaNames.NAME: \"CNN\",\n",
    "    client.repository.ModelMetaNames.TYPE: \"tensorflow_2.7\",\n",
    "    client.repository.ModelMetaNames.SOFTWARE_SPEC_UID: software_spec_uid\n",
    "})\n",
    "\n",
    "model_id = client.repository.get_model_id(model_details)\n",
    "model_id\n",
    "'19b34bdf-1aaa-4638-97e9-b2fc0d3231cf'\n",
    "client.repository.download(model_id, \"my_model.tar.gz\")\n",
    "Successfully saved model content to file: 'my_model.tar.gz'\n",
    "'/home/wsuser/work/my_model.tar.gz'\n",
    " pwd\n",
    "'/home/wsuser/work'\n",
    "import numpy as np\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Flatten, Conv2D, MaxPooling2D\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "import os, types\n",
    "import pandas as pd\n",
    "from botocore.client import Config\n",
    "import ibm_boto3\n",
    "\n",
    "def __iter__(self): return 0\n",
    "\n",
    "# @hidden_cell\n",
    "# The following code accesses a file in your IBM Cloud Object Storage. It includes your credentials.\n",
    "# You might want to remove those credentials before you share the notebook.\n",
    "cos_client = ibm_boto3.client(service_name='s3',\n",
    "    ibm_api_key_id='eqRr_BuHHp9Di6TVmW-MGXHyPXtsbYlsKBxJDrYcV7Yn',\n",
    "    ibm_auth_endpoint=\"https://iam.cloud.ibm.com/oidc/token\",\n",
    "    config=Config(signature_version='oauth'),\n",
    "    endpoint_url='https://s3.private.us.cloud-object-storage.appdomain.cloud')\n",
    "\n",
    "bucket = 'naturaldisastersintensityanalysis-donotdelete-pr-wij7ez8jjgzubp'\n",
    "object_key = 'dataset.zip'\n",
    "\n",
    "streaming_body_2 = cos_client.get_object(Bucket=bucket, Key=object_key)['Body']\n",
    "\n",
    "# Your data file was loaded into a botocore.response.StreamingBody object.\n",
    "# Please read the documentation of ibm_boto3 and pandas to learn more about the possibilities to load the data.\n",
    "# ibm_boto3 documentation: https://ibm.github.io/ibm-cos-sdk-python/\n",
    "# pandas documentation: http://pandas.pydata.org/\n",
    "from io import BytesIO\n",
    "import zipfile\n",
    "unzip = zipfile.ZipFile(BytesIO(streaming_body_2.read()),'r')\n",
    "file_paths = unzip.namelist()\n",
    "for path in file_paths:\n",
    "    unzip.extract(path)\n",
    "data_path = '/home/wsuser/work/Dataset/'\n",
    "batch_size = 32\n",
    "target_size = (64, 64)\n",
    "train_datagen = ImageDataGenerator(rescale=1./255,\n",
    "                                   shear_range=0.2,\n",
    "                                   zoom_range=0.2,\n",
    "                                   width_shift_range=0.1,\n",
    "                                   height_shift_range=0.1,\n",
    "                                   horizontal_flip=True,\n",
    "                                   validation_split=0.2)\n",
    "\n",
    "test_datagen = ImageDataGenerator(rescale=1. / 255, validation_split=0.2)\n",
    "X_train = train_datagen.flow_from_directory('/home/wsuser/work/dataset/train_set',\n",
    "                                            target_size=(64, 64),\n",
    "                                            batch_size=32,\n",
    "                                            color_mode=\"rgb\",\n",
    "                                            subset=\"training\",\n",
    "                                            class_mode='categorical')\n",
    "\n",
    "\n",
    "\n",
    "X_test = test_datagen.flow_from_directory('/home/wsuser/work/dataset/test_set',\n",
    "                                          target_size=(64, 64),\n",
    "                                          batch_size=32,\n",
    "                                          color_mode=\"rgb\",\n",
    "                                          subset=\"validation\",\n",
    "                                          class_mode='categorical')\n",
    "Found 595 images belonging to 4 classes.\n",
    "Found 37 images belonging to 4 classes.\n",
    "model = Sequential()\n",
    "model.add(Conv2D(32, (3, 3), input_shape=(64, 64, 3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Conv2D(32, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Flatten())\n",
    "\n",
    "model.add(Dense(units=128, activation='relu'))\n",
    "model.add(Dense(units=4, activation='softmax'))\n",
    "model.summary()\n",
    "Model: \"sequential\"\n",
    "_________________________________________________________________\n",
    " Layer (type)                Output Shape              Param #   \n",
    "=================================================================\n",
    " conv2d (Conv2D)             (None, 62, 62, 32)        896       \n",
    "                                                                 \n",
    " max_pooling2d (MaxPooling2D  (None, 31, 31, 32)       0         \n",
    " )                                                               \n",
    "                                                                 \n",
    " conv2d_1 (Conv2D)           (None, 29, 29, 32)        9248      \n",
    "                                                                 \n",
    " max_pooling2d_1 (MaxPooling  (None, 14, 14, 32)       0         \n",
    " 2D)                                                             \n",
    "                                                                 \n",
    " flatten (Flatten)           (None, 6272)              0         \n",
    "                                                                 \n",
    " dense (Dense)               (None, 128)               802944    \n",
    "                                                                 \n",
    " dense_1 (Dense)             (None, 4)                 516       \n",
    "                                                                 \n",
    "=================================================================\n",
    "Total params: 813,604\n",
    "Trainable params: 813,604\n",
    "Non-trainable params: 0\n",
    "_________________________________________________________________\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "model.fit(X_train, \n",
    "          steps_per_epoch=len(X_train), \n",
    "          epochs=20,\n",
    "          validation_data=X_test,\n",
    "          validation_steps=len(X_test))\n",
    "Epoch 1/20\n",
    "19/19 [==============================] - 28s 1s/step - loss: 1.2825 - accuracy: 0.4017 - val_loss: 1.1511 - val_accuracy: 0.5946\n",
    "Epoch 2/20\n",
    "19/19 [==============================] - 25s 1s/step - loss: 1.0187 - accuracy: 0.5933 - val_loss: 0.9829 - val_accuracy: 0.6757\n",
    "Epoch 3/20\n",
    "19/19 [==============================] - 25s 1s/step - loss: 0.8670 - accuracy: 0.6571 - val_loss: 1.2125 - val_accuracy: 0.4865\n",
    "Epoch 4/20\n",
    "19/19 [==============================] - 26s 1s/step - loss: 0.8239 - accuracy: 0.6723 - val_loss: 0.9556 - val_accuracy: 0.6757\n",
    "Epoch 5/20\n",
    "19/19 [==============================] - 25s 1s/step - loss: 0.7818 - accuracy: 0.6840 - val_loss: 1.0185 - val_accuracy: 0.6757\n",
    "Epoch 6/20\n",
    "19/19 [==============================] - 26s 1s/step - loss: 0.6352 - accuracy: 0.7714 - val_loss: 0.9754 - val_accuracy: 0.7568\n",
    "Epoch 7/20\n",
    "19/19 [==============================] - 26s 1s/step - loss: 0.5867 - accuracy: 0.7681 - val_loss: 0.8624 - val_accuracy: 0.7568\n",
    "Epoch 8/20\n",
    "19/19 [==============================] - 25s 1s/step - loss: 0.6245 - accuracy: 0.7681 - val_loss: 0.8863 - val_accuracy: 0.7027\n",
    "Epoch 9/20\n",
    "19/19 [==============================] - 25s 1s/step - loss: 0.6180 - accuracy: 0.7664 - val_loss: 1.5044 - val_accuracy: 0.6757\n",
    "Epoch 10/20\n",
    "19/19 [==============================] - 25s 1s/step - loss: 0.5976 - accuracy: 0.7765 - val_loss: 1.0201 - val_accuracy: 0.6757\n",
    "Epoch 11/20\n",
    "19/19 [==============================] - 25s 1s/step - loss: 0.5209 - accuracy: 0.8050 - val_loss: 0.8570 - val_accuracy: 0.7027\n",
    "Epoch 12/20\n",
    "19/19 [==============================] - 25s 1s/step - loss: 0.5374 - accuracy: 0.7899 - val_loss: 1.0046 - val_accuracy: 0.7297\n",
    "Epoch 13/20\n",
    "19/19 [==============================] - 25s 1s/step - loss: 0.5231 - accuracy: 0.7983 - val_loss: 0.8088 - val_accuracy: 0.7568\n",
    "Epoch 14/20\n",
    "19/19 [==============================] - 25s 1s/step - loss: 0.4615 - accuracy: 0.8303 - val_loss: 0.8695 - val_accuracy: 0.7568\n",
    "Epoch 15/20\n",
    "19/19 [==============================] - 26s 1s/step - loss: 0.4904 - accuracy: 0.8134 - val_loss: 1.0314 - val_accuracy: 0.7568\n",
    "Epoch 16/20\n",
    "19/19 [==============================] - 26s 1s/step - loss: 0.4355 - accuracy: 0.8286 - val_loss: 0.9395 - val_accuracy: 0.7568\n",
    "Epoch 17/20\n",
    "19/19 [==============================] - 25s 1s/step - loss: 0.4891 - accuracy: 0.8185 - val_loss: 0.9327 - val_accuracy: 0.7838\n",
    "Epoch 18/20\n",
    "19/19 [==============================] - 26s 1s/step - loss: 0.3950 - accuracy: 0.8487 - val_loss: 1.0022 - val_accuracy: 0.7568\n",
    "Epoch 19/20\n",
    "19/19 [==============================] - 25s 1s/step - loss: 0.4382 - accuracy: 0.8370 - val_loss: 0.9419 - val_accuracy: 0.8378\n",
    "Epoch 20/20\n",
    "19/19 [==============================] - 25s 1s/step - loss: 0.3950 - accuracy: 0.8387 - val_loss: 1.1659 - val_accuracy: 0.7297\n",
    "model.save(\"disaster.h5\")\n",
    "!tar -zcvf disaster.tgz disaster.h5\n",
    "disaster.h5\n",
    "ls\n",
    "dataset/  disaster.h5  disaster.tgz\n",
    "!pip install watson-machine-learning-client\n",
    "Collecting watson-machine-learning-client\n",
    "  Downloading watson_machine_learning_client-1.0.391-py3-none-any.whl (538 kB)\n",
    "     |████████████████████████████████| 538 kB 12.9 MB/s eta 0:00:01\n",
    "Requirement already satisfied: tqdm in /opt/conda/envs/Python-3.9/lib/python3.9/site-packages (from watson-machine-learning-client) (4.62.3)\n",
    "Requirement already satisfied: requests in /opt/conda/envs/Python-3.9/lib/python3.9/site-packages (from watson-machine-learning-client) (2.26.0)\n",
    "Requirement already satisfied: pandas in /opt/conda/envs/Python-3.9/lib/python3.9/site-packages (from watson-machine-learning-client) (1.3.4)\n",
    "Requirement already satisfied: urllib3 in /opt/conda/envs/Python-3.9/lib/python3.9/site-packages (from watson-machine-learning-client) (1.26.7)\n",
    "Requirement already satisfied: ibm-cos-sdk in /opt/conda/envs/Python-3.9/lib/python3.9/site-packages (from watson-machine-learning-client) (2.11.0)\n",
    "Requirement already satisfied: boto3 in /opt/conda/envs/Python-3.9/lib/python3.9/site-packages (from watson-machine-learning-client) (1.18.21)\n",
    "Requirement already satisfied: lomond in /opt/conda/envs/Python-3.9/lib/python3.9/site-packages (from watson-machine-learning-client) (0.3.3)\n",
    "Requirement already satisfied: tabulate in /opt/conda/envs/Python-3.9/lib/python3.9/site-packages (from watson-machine-learning-client) (0.8.9)\n",
    "Requirement already satisfied: certifi in /opt/conda/envs/Python-3.9/lib/python3.9/site-packages (from watson-machine-learning-client) (2022.9.24)\n",
    "Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in /opt/conda/envs/Python-3.9/lib/python3.9/site-packages (from boto3->watson-machine-learning-client) (0.10.0)\n",
    "Requirement already satisfied: botocore<1.22.0,>=1.21.21 in /opt/conda/envs/Python-3.9/lib/python3.9/site-packages (from boto3->watson-machine-learning-client) (1.21.41)\n",
    "Requirement already satisfied: s3transfer<0.6.0,>=0.5.0 in /opt/conda/envs/Python-3.9/lib/python3.9/site-packages (from boto3->watson-machine-learning-client) (0.5.0)\n",
    "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /opt/conda/envs/Python-3.9/lib/python3.9/site-packages (from botocore<1.22.0,>=1.21.21->boto3->watson-machine-learning-client) (2.8.2)\n",
    "Requirement already satisfied: six>=1.5 in /opt/conda/envs/Python-3.9/lib/python3.9/site-packages (from python-dateutil<3.0.0,>=2.1->botocore<1.22.0,>=1.21.21->boto3->watson-machine-learning-client) (1.15.0)\n",
    "Requirement already satisfied: ibm-cos-sdk-s3transfer==2.11.0 in /opt/conda/envs/Python-3.9/lib/python3.9/site-packages (from ibm-cos-sdk->watson-machine-learning-client) (2.11.0)\n",
    "Requirement already satisfied: ibm-cos-sdk-core==2.11.0 in /opt/conda/envs/Python-3.9/lib/python3.9/site-packages (from ibm-cos-sdk->watson-machine-learning-client) (2.11.0)\n",
    "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/envs/Python-3.9/lib/python3.9/site-packages (from requests->watson-machine-learning-client) (3.3)\n",
    "Requirement already satisfied: charset-normalizer~=2.0.0 in /opt/conda/envs/Python-3.9/lib/python3.9/site-packages (from requests->watson-machine-learning-client) (2.0.4)\n",
    "Requirement already satisfied: pytz>=2017.3 in /opt/conda/envs/Python-3.9/lib/python3.9/site-packages (from pandas->watson-machine-learning-client) (2021.3)\n",
    "Requirement already satisfied: numpy>=1.17.3 in /opt/conda/envs/Python-3.9/lib/python3.9/site-packages (from pandas->watson-machine-learning-client) (1.20.3)\n",
    "Installing collected packages: watson-machine-learning-client\n",
    "Successfully installed watson-machine-learning-client-1.0.391\n",
    "from ibm_watson_machine_learning import APIClient\n",
    "\n",
    "API_KEY = \"dI8836cei5gsTnRg5IXx2Jla_HxwNj1-FyYdDTq1oHkV\"\n",
    "\n",
    "wml_credentials = {\n",
    "    \"url\": \"https://us-south.ml.cloud.ibm.com\",\n",
    "    \"apikey\": API_KEY\n",
    "}\n",
    "\n",
    "client = APIClient(wml_credentials)\n",
    "client=APIClient(wml_credentials)\n",
    "def guid_from_space_name(client, space_name):\n",
    "    space = client.spaces.get_details()\n",
    "    return(next(item for item in space['resources'] if item['entity']['name'] == space_name)['metadata']['id'])\n",
    "space_uid = guid_from_space_name(client, 'Natural Disasters Intensity Analysis')\n",
    "print(\"Space UID: \", space_uid)\n",
    "Space UID:  eaa2304c-ca2e-4e95-a4a0-23809b39bdda\n",
    "client.set.default_space(space_uid)\n",
    "'SUCCESS'\n",
    "client.software_specifications.list()\n",
    "-----------------------------  ------------------------------------  ----\n",
    "NAME                           ASSET_ID                              TYPE\n",
    "default_py3.6                  0062b8c9-8b7d-44a0-a9b9-46c416adcbd9  base\n",
    "kernel-spark3.2-scala2.12      020d69ce-7ac1-5e68-ac1a-31189867356a  base\n",
    "pytorch-onnx_1.3-py3.7-edt     069ea134-3346-5748-b513-49120e15d288  base\n",
    "scikit-learn_0.20-py3.6        09c5a1d0-9c1e-4473-a344-eb7b665ff687  base\n",
    "spark-mllib_3.0-scala_2.12     09f4cff0-90a7-5899-b9ed-1ef348aebdee  base\n",
    "pytorch-onnx_rt22.1-py3.9      0b848dd4-e681-5599-be41-b5f6fccc6471  base\n",
    "ai-function_0.1-py3.6          0cdb0f1e-5376-4f4d-92dd-da3b69aa9bda  base\n",
    "shiny-r3.6                     0e6e79df-875e-4f24-8ae9-62dcc2148306  base\n",
    "tensorflow_2.4-py3.7-horovod   1092590a-307d-563d-9b62-4eb7d64b3f22  base\n",
    "pytorch_1.1-py3.6              10ac12d6-6b30-4ccd-8392-3e922c096a92  base\n",
    "tensorflow_1.15-py3.6-ddl      111e41b3-de2d-5422-a4d6-bf776828c4b7  base\n",
    "autoai-kb_rt22.2-py3.10        125b6d9a-5b1f-5e8d-972a-b251688ccf40  base\n",
    "runtime-22.1-py3.9             12b83a17-24d8-5082-900f-0ab31fbfd3cb  base\n",
    "scikit-learn_0.22-py3.6        154010fa-5b3b-4ac1-82af-4d5ee5abbc85  base\n",
    "default_r3.6                   1b70aec3-ab34-4b87-8aa0-a4a3c8296a36  base\n",
    "pytorch-onnx_1.3-py3.6         1bc6029a-cc97-56da-b8e0-39c3880dbbe7  base\n",
    "kernel-spark3.3-r3.6           1c9e5454-f216-59dd-a20e-474a5cdf5988  base\n",
    "pytorch-onnx_rt22.1-py3.9-edt  1d362186-7ad5-5b59-8b6c-9d0880bde37f  base\n",
    "tensorflow_2.1-py3.6           1eb25b84-d6ed-5dde-b6a5-3fbdf1665666  base\n",
    "spark-mllib_3.2                20047f72-0a98-58c7-9ff5-a77b012eb8f5  base\n",
    "tensorflow_2.4-py3.8-horovod   217c16f6-178f-56bf-824a-b19f20564c49  base\n",
    "runtime-22.1-py3.9-cuda        26215f05-08c3-5a41-a1b0-da66306ce658  base\n",
    "do_py3.8                       295addb5-9ef9-547e-9bf4-92ae3563e720  base\n",
    "autoai-ts_3.8-py3.8            2aa0c932-798f-5ae9-abd6-15e0c2402fb5  base\n",
    "tensorflow_1.15-py3.6          2b73a275-7cbf-420b-a912-eae7f436e0bc  base\n",
    "kernel-spark3.3-py3.9          2b7961e2-e3b1-5a8c-a491-482c8368839a  base\n",
    "pytorch_1.2-py3.6              2c8ef57d-2687-4b7d-acce-01f94976dac1  base\n",
    "spark-mllib_2.3                2e51f700-bca0-4b0d-88dc-5c6791338875  base\n",
    "pytorch-onnx_1.1-py3.6-edt     32983cea-3f32-4400-8965-dde874a8d67e  base\n",
    "spark-mllib_3.0-py37           36507ebe-8770-55ba-ab2a-eafe787600e9  base\n",
    "spark-mllib_2.4                390d21f8-e58b-4fac-9c55-d7ceda621326  base\n",
    "autoai-ts_rt22.2-py3.10        396b2e83-0953-5b86-9a55-7ce1628a406f  base\n",
    "xgboost_0.82-py3.6             39e31acd-5f30-41dc-ae44-60233c80306e  base\n",
    "pytorch-onnx_1.2-py3.6-edt     40589d0e-7019-4e28-8daa-fb03b6f4fe12  base\n",
    "pytorch-onnx_rt22.2-py3.10     40e73f55-783a-5535-b3fa-0c8b94291431  base\n",
    "default_r36py38                41c247d3-45f8-5a71-b065-8580229facf0  base\n",
    "autoai-ts_rt22.1-py3.9         4269d26e-07ba-5d40-8f66-2d495b0c71f7  base\n",
    "autoai-obm_3.0                 42b92e18-d9ab-567f-988a-4240ba1ed5f7  base\n",
    "pmml-3.0_4.3                   493bcb95-16f1-5bc5-bee8-81b8af80e9c7  base\n",
    "spark-mllib_2.4-r_3.6          49403dff-92e9-4c87-a3d7-a42d0021c095  base\n",
    "xgboost_0.90-py3.6             4ff8d6c2-1343-4c18-85e1-689c965304d3  base\n",
    "pytorch-onnx_1.1-py3.6         50f95b2a-bc16-43bb-bc94-b0bed208c60b  base\n",
    "autoai-ts_3.9-py3.8            52c57136-80fa-572e-8728-a5e7cbb42cde  base\n",
    "spark-mllib_2.4-scala_2.11     55a70f99-7320-4be5-9fb9-9edb5a443af5  base\n",
    "spark-mllib_3.0                5c1b0ca2-4977-5c2e-9439-ffd44ea8ffe9  base\n",
    "autoai-obm_2.0                 5c2e37fa-80b8-5e77-840f-d912469614ee  base\n",
    "spss-modeler_18.1              5c3cad7e-507f-4b2a-a9a3-ab53a21dee8b  base\n",
    "cuda-py3.8                     5d3232bf-c86b-5df4-a2cd-7bb870a1cd4e  base\n",
    "autoai-kb_3.1-py3.7            632d4b22-10aa-5180-88f0-f52dfb6444d7  base\n",
    "pytorch-onnx_1.7-py3.8         634d3cdc-b562-5bf9-a2d4-ea90a478456b  base\n",
    "-----------------------------  ------------------------------------  ----\n",
    "Note: Only first 50 records were displayed. To display more use 'limit' parameter.\n",
    "software_spec_uid = client.software_specifications.get_uid_by_name(\"runtime-22.1-py3.9\")\n",
    "software_spec_uid\n",
    "'12b83a17-24d8-5082-900f-0ab31fbfd3cb'\n",
    "model_details = client.repository.store_model(model=\"disaster.tgz\", meta_props={\n",
    "    client.repository.ModelMetaNames.NAME: \"CNN\",\n",
    "    client.repository.ModelMetaNames.TYPE: \"tensorflow_2.7\",\n",
    "    client.repository.ModelMetaNames.SOFTWARE_SPEC_UID: software_spec_uid\n",
    "})\n",
    "\n",
    "model_id = client.repository.get_model_id(model_details)\n",
    "model_id\n",
    "'19b34bdf-1aaa-4638-97e9-b2fc0d3231cf'\n",
    "client.repository.download(model_id, \"my_model.tar.gz\")\n",
    "Successfully saved model content to file: 'my_model.tar.gz'\n",
    "'/home/wsuser/work/my_model.tar.gz'\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
